{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "colab_triage.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dssg/triage/blob/kit_colab_triage/example/colab/colab_triage.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ix00QRsvd45"
      },
      "source": [
        "# Colab Triage\n",
        "\n",
        "This notebook provides a quick, interactive tutorial for `triage`, a python machine learning pipeline for social good problems.\n",
        "\n",
        "For the tutorial, we'll be using a sample of the data provided by DonorsChoose to the 2014 KDD Cup -- the full dataset and some details about it can be found [here](https://www.kaggle.com/c/kdd-cup-2014-predicting-excitement-at-donors-choose/data). DonorsChoose is a crowdfunding platform for teachers to seek funding for projects and resources from the community. Like other crowdfunding sites, a project is only funded if it reaches its goal (a project will expire if it hasn't been fully funded after 4 months).\n",
        "\n",
        "For our purposes here, we imagine that donors choose has a new program that will help projects at risk of not being fully funded by providing a review from a digital content expert. Our job is to help them identify those projects.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtAMABPn971u"
      },
      "source": [
        "## Getting Set Up\n",
        "\n",
        "We'll need a few dependencies to run triage in a colab notebook:\n",
        "- A local postgresql server (we'll use version 11)\n",
        "- A simplified dataset loaded into this database (we'll use data from DonorsChoose)\n",
        "- Triage and its dependencies (we'll use the current version in pypi)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-htIBoS7N4gK",
        "outputId": "eb222091-e254-49b1-c4d1-558d6e35430e"
      },
      "source": [
        "# Install and start postgresql-11 server\n",
        "!sudo apt-get -y -qq update\n",
        "!wget --quiet -O - https://www.postgresql.org/media/keys/ACCC4CF8.asc | sudo apt-key add -\n",
        "!echo \"deb http://apt.postgresql.org/pub/repos/apt/ `lsb_release -cs`-pgdg main\" |sudo tee  /etc/apt/sources.list.d/pgdg.list\n",
        "!sudo apt-get -y -qq update\n",
        "!sudo apt-get -y -qq install postgresql-11 postgresql-client-11\n",
        "!sudo service postgresql start\n",
        "\n",
        "# Setup a password `postgres` for username `postgres`\n",
        "!sudo -u postgres psql -U postgres -c \"ALTER USER postgres PASSWORD 'postgres';\"\n",
        "\n",
        "# Setup a database with name `donors_choose` to be used\n",
        "!sudo -u postgres psql -U postgres -c 'DROP DATABASE IF EXISTS donors_choose;'\n",
        "!sudo -u postgres psql -U postgres -c 'CREATE DATABASE donors_choose;'\n",
        "\n",
        "# Environment variables for connecting to the database\n",
        "%env DEMO_DATABASE_NAME=donors_choose\n",
        "%env DEMO_DATABASE_HOST=localhost\n",
        "%env DEMO_DATABASE_PORT=5432\n",
        "%env DEMO_DATABASE_USER=postgres\n",
        "%env DEMO_DATABASE_PASS=postgres"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OK\n",
            "deb http://apt.postgresql.org/pub/repos/apt/ bionic-pgdg main\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 16.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package cron.\n",
            "(Reading database ... 155222 files and directories currently installed.)\n",
            "Preparing to unpack .../00-cron_3.0pl1-128.1ubuntu1_amd64.deb ...\n",
            "Unpacking cron (3.0pl1-128.1ubuntu1) ...\n",
            "Selecting previously unselected package logrotate.\n",
            "Preparing to unpack .../01-logrotate_3.11.0-0.1ubuntu1_amd64.deb ...\n",
            "Unpacking logrotate (3.11.0-0.1ubuntu1) ...\n",
            "Selecting previously unselected package netbase.\n",
            "Preparing to unpack .../02-netbase_5.4_all.deb ...\n",
            "Unpacking netbase (5.4) ...\n",
            "Selecting previously unselected package libcommon-sense-perl.\n",
            "Preparing to unpack .../03-libcommon-sense-perl_3.74-2build2_amd64.deb ...\n",
            "Unpacking libcommon-sense-perl (3.74-2build2) ...\n",
            "Selecting previously unselected package libjson-perl.\n",
            "Preparing to unpack .../04-libjson-perl_2.97001-1_all.deb ...\n",
            "Unpacking libjson-perl (2.97001-1) ...\n",
            "Selecting previously unselected package libtypes-serialiser-perl.\n",
            "Preparing to unpack .../05-libtypes-serialiser-perl_1.0-1_all.deb ...\n",
            "Unpacking libtypes-serialiser-perl (1.0-1) ...\n",
            "Selecting previously unselected package libjson-xs-perl.\n",
            "Preparing to unpack .../06-libjson-xs-perl_3.040-1_amd64.deb ...\n",
            "Unpacking libjson-xs-perl (3.040-1) ...\n",
            "Preparing to unpack .../07-libpq-dev_14.1-1.pgdg18.04+1_amd64.deb ...\n",
            "Unpacking libpq-dev (14.1-1.pgdg18.04+1) over (10.19-0ubuntu0.18.04.1) ...\n",
            "Preparing to unpack .../08-libpq5_14.1-1.pgdg18.04+1_amd64.deb ...\n",
            "Unpacking libpq5:amd64 (14.1-1.pgdg18.04+1) over (10.19-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package pgdg-keyring.\n",
            "Preparing to unpack .../09-pgdg-keyring_2018.2_all.deb ...\n",
            "Unpacking pgdg-keyring (2018.2) ...\n",
            "Selecting previously unselected package postgresql-client-common.\n",
            "Preparing to unpack .../10-postgresql-client-common_232.pgdg18.04+1_all.deb ...\n",
            "Unpacking postgresql-client-common (232.pgdg18.04+1) ...\n",
            "Selecting previously unselected package postgresql-client-11.\n",
            "Preparing to unpack .../11-postgresql-client-11_11.14-1.pgdg18.04+1_amd64.deb ...\n",
            "Unpacking postgresql-client-11 (11.14-1.pgdg18.04+1) ...\n",
            "Selecting previously unselected package ssl-cert.\n",
            "Preparing to unpack .../12-ssl-cert_1.0.39_all.deb ...\n",
            "Unpacking ssl-cert (1.0.39) ...\n",
            "Selecting previously unselected package postgresql-common.\n",
            "Preparing to unpack .../13-postgresql-common_232.pgdg18.04+1_all.deb ...\n",
            "Adding 'diversion of /usr/bin/pg_config to /usr/bin/pg_config.libpq-dev by postgresql-common'\n",
            "Unpacking postgresql-common (232.pgdg18.04+1) ...\n",
            "Selecting previously unselected package postgresql-11.\n",
            "Preparing to unpack .../14-postgresql-11_11.14-1.pgdg18.04+1_amd64.deb ...\n",
            "Unpacking postgresql-11 (11.14-1.pgdg18.04+1) ...\n",
            "Selecting previously unselected package sysstat.\n",
            "Preparing to unpack .../15-sysstat_11.6.1-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking sysstat (11.6.1-1ubuntu0.1) ...\n",
            "Setting up libcommon-sense-perl (3.74-2build2) ...\n",
            "Setting up sysstat (11.6.1-1ubuntu0.1) ...\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76.)\n",
            "debconf: falling back to frontend: Readline\n",
            "\n",
            "Creating config file /etc/default/sysstat with new version\n",
            "update-alternatives: using /usr/bin/sar.sysstat to provide /usr/bin/sar (sar) in auto mode\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/sysstat.service → /lib/systemd/system/sysstat.service.\n",
            "Setting up ssl-cert (1.0.39) ...\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76.)\n",
            "debconf: falling back to frontend: Readline\n",
            "Setting up libtypes-serialiser-perl (1.0-1) ...\n",
            "Setting up libpq5:amd64 (14.1-1.pgdg18.04+1) ...\n",
            "Setting up pgdg-keyring (2018.2) ...\n",
            "Removing apt.postgresql.org key from trusted.gpg: OK\n",
            "Setting up libjson-perl (2.97001-1) ...\n",
            "Setting up cron (3.0pl1-128.1ubuntu1) ...\n",
            "Adding group `crontab' (GID 110) ...\n",
            "Done.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/cron.service → /lib/systemd/system/cron.service.\n",
            "update-rc.d: warning: start and stop actions are no longer supported; falling back to defaults\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of start.\n",
            "Setting up logrotate (3.11.0-0.1ubuntu1) ...\n",
            "Setting up netbase (5.4) ...\n",
            "Setting up libpq-dev (14.1-1.pgdg18.04+1) ...\n",
            "Setting up libjson-xs-perl (3.040-1) ...\n",
            "Setting up postgresql-client-common (232.pgdg18.04+1) ...\n",
            "Setting up postgresql-common (232.pgdg18.04+1) ...\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76.)\n",
            "debconf: falling back to frontend: Readline\n",
            "Adding user postgres to group ssl-cert\n",
            "\n",
            "Creating config file /etc/postgresql-common/createcluster.conf with new version\n",
            "Building PostgreSQL dictionaries from installed myspell/hunspell packages...\n",
            "Removing obsolete dictionary files:\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/postgresql.service → /lib/systemd/system/postgresql.service.\n",
            "Setting up postgresql-client-11 (11.14-1.pgdg18.04+1) ...\n",
            "update-alternatives: using /usr/share/postgresql/11/man/man1/psql.1.gz to provide /usr/share/man/man1/psql.1.gz (psql.1.gz) in auto mode\n",
            "Setting up postgresql-11 (11.14-1.pgdg18.04+1) ...\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76.)\n",
            "debconf: falling back to frontend: Readline\n",
            "Creating new PostgreSQL cluster 11/main ...\n",
            "/usr/lib/postgresql/11/bin/initdb -D /var/lib/postgresql/11/main --auth-local peer --auth-host md5\n",
            "The files belonging to this database system will be owned by user \"postgres\".\n",
            "This user must also own the server process.\n",
            "\n",
            "The database cluster will be initialized with locale \"en_US.UTF-8\".\n",
            "The default database encoding has accordingly been set to \"UTF8\".\n",
            "The default text search configuration will be set to \"english\".\n",
            "\n",
            "Data page checksums are disabled.\n",
            "\n",
            "fixing permissions on existing directory /var/lib/postgresql/11/main ... ok\n",
            "creating subdirectories ... ok\n",
            "selecting default max_connections ... 100\n",
            "selecting default shared_buffers ... 128MB\n",
            "selecting default timezone ... Etc/UTC\n",
            "selecting dynamic shared memory implementation ... posix\n",
            "creating configuration files ... ok\n",
            "running bootstrap script ... ok\n",
            "performing post-bootstrap initialization ... ok\n",
            "syncing data to disk ... ok\n",
            "\n",
            "Success. You can now start the database server using:\n",
            "\n",
            "    pg_ctlcluster 11 main start\n",
            "\n",
            "update-alternatives: using /usr/share/postgresql/11/man/man1/postmaster.1.gz to provide /usr/share/man/man1/postmaster.1.gz (postmaster.1.gz) in auto mode\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of start.\n",
            "Processing triggers for systemd (237-3ubuntu10.52) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            " * Starting PostgreSQL 11 database server\n",
            "   ...done.\n",
            "ALTER ROLE\n",
            "NOTICE:  database \"donors_choose\" does not exist, skipping\n",
            "DROP DATABASE\n",
            "CREATE DATABASE\n",
            "env: DEMO_DATABASE_NAME=donors_choose\n",
            "env: DEMO_DATABASE_HOST=localhost\n",
            "env: DEMO_DATABASE_PORT=5432\n",
            "env: DEMO_DATABASE_USER=postgres\n",
            "env: DEMO_DATABASE_PASS=postgres\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mWNhJ2rOVtS"
      },
      "source": [
        "# Download sampled DonorsChoose data and load it into our postgres server\n",
        "!curl -s -OL https://dsapp-public-data-migrated.s3.us-west-2.amazonaws.com/donors_sampled_20210920_v3.dmp\n",
        "!PGPASSWORD=$DEMO_DATABASE_PASS pg_restore -h $DEMO_DATABASE_HOST -p $DEMO_DATABASE_PORT -d $DEMO_DATABASE_NAME -U $DEMO_DATABASE_USER -O -j 8 donors_sampled_20210920_v3.dmp"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "t5E-9VRjRlSk",
        "outputId": "e1c48a73-910e-4470-ea78-e7c19da446c4"
      },
      "source": [
        "# Install triage and its dependencies\n",
        "!pip install triage"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting triage\n",
            "  Downloading triage-5.1.0-py2.py3-none-any.whl (250 kB)\n",
            "\u001b[K     |████████████████████████████████| 250 kB 27.9 MB/s \n",
            "\u001b[?25hCollecting graphviz==0.14\n",
            "  Downloading graphviz-0.14-py2.py3-none-any.whl (18 kB)\n",
            "Collecting python-dateutil==2.8.1\n",
            "  Downloading python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)\n",
            "\u001b[K     |████████████████████████████████| 227 kB 73.1 MB/s \n",
            "\u001b[?25hCollecting PyYAML==5.4.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 53.0 MB/s \n",
            "\u001b[?25hCollecting Dickens==1.0.1\n",
            "  Downloading Dickens-1.0.1.tar.gz (2.3 kB)\n",
            "Collecting wrapt==1.12.1\n",
            "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
            "Collecting requests==2.24.0\n",
            "  Downloading requests-2.24.0-py2.py3-none-any.whl (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 380 kB/s \n",
            "\u001b[?25hCollecting sqlalchemy-postgres-copy==0.5.0\n",
            "  Downloading sqlalchemy_postgres_copy-0.5.0-py2.py3-none-any.whl (6.6 kB)\n",
            "Collecting pebble==4.5.3\n",
            "  Downloading Pebble-4.5.3-py2.py3-none-any.whl (24 kB)\n",
            "Collecting coloredlogs==14.0\n",
            "  Downloading coloredlogs-14.0-py2.py3-none-any.whl (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 2.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: sqlparse==0.4.2 in /usr/local/lib/python3.7/dist-packages (from triage) (0.4.2)\n",
            "Collecting boto3==1.14.45\n",
            "  Downloading boto3-1.14.45-py2.py3-none-any.whl (129 kB)\n",
            "\u001b[K     |████████████████████████████████| 129 kB 57.3 MB/s \n",
            "\u001b[?25hCollecting inflection==0.5.0\n",
            "  Downloading inflection-0.5.0-py2.py3-none-any.whl (5.8 kB)\n",
            "Collecting ohio==0.5.0\n",
            "  Downloading ohio-0.5.0-py3-none-any.whl (26 kB)\n",
            "Collecting psycopg2-binary==2.8.5\n",
            "  Downloading psycopg2_binary-2.8.5-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 55.7 MB/s \n",
            "\u001b[?25hCollecting argcmdr==0.7.0\n",
            "  Downloading argcmdr-0.7.0-py3-none-any.whl (33 kB)\n",
            "Collecting adjustText==0.7.3\n",
            "  Downloading adjustText-0.7.3.tar.gz (7.5 kB)\n",
            "Collecting verboselogs==1.7\n",
            "  Downloading verboselogs-1.7-py2.py3-none-any.whl (11 kB)\n",
            "Collecting alembic==1.4.2\n",
            "  Downloading alembic-1.4.2.tar.gz (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 44.7 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: matplotlib==3.2.2 in /usr/local/lib/python3.7/dist-packages (from triage) (3.2.2)\n",
            "Collecting signalled-timeout==1.0.0\n",
            "  Downloading signalled-timeout-1.0.0.tar.gz (2.7 kB)\n",
            "Requirement already satisfied: click==7.1.2 in /usr/local/lib/python3.7/dist-packages (from triage) (7.1.2)\n",
            "Collecting aequitas==0.42.0\n",
            "  Downloading aequitas-0.42.0-py3-none-any.whl (2.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2 MB 29.5 MB/s \n",
            "\u001b[?25hCollecting SQLAlchemy==1.3.18\n",
            "  Downloading SQLAlchemy-1.3.18-cp37-cp37m-manylinux2010_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 32.3 MB/s \n",
            "\u001b[?25hCollecting scipy==1.5.0\n",
            "  Downloading scipy-1.5.0-cp37-cp37m-manylinux1_x86_64.whl (25.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 25.9 MB 38.4 MB/s \n",
            "\u001b[?25hCollecting s3fs==0.4.2\n",
            "  Downloading s3fs-0.4.2-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: retrying==1.3.3 in /usr/local/lib/python3.7/dist-packages (from triage) (1.3.3)\n",
            "Collecting numpy==1.21.1\n",
            "  Downloading numpy-1.21.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 15.7 MB 34.4 MB/s \n",
            "\u001b[?25hCollecting scikit-learn==0.23.1\n",
            "  Downloading scikit_learn-0.23.1-cp37-cp37m-manylinux1_x86_64.whl (6.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.8 MB 44.1 MB/s \n",
            "\u001b[?25hCollecting pandas==1.0.5\n",
            "  Downloading pandas-1.0.5-cp37-cp37m-manylinux1_x86_64.whl (10.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1 MB 31.2 MB/s \n",
            "\u001b[?25hCollecting seaborn==0.10.1\n",
            "  Downloading seaborn-0.10.1-py3-none-any.whl (215 kB)\n",
            "\u001b[K     |████████████████████████████████| 215 kB 65.1 MB/s \n",
            "\u001b[?25hCollecting tabulate==0.8.2\n",
            "  Downloading tabulate-0.8.2.tar.gz (45 kB)\n",
            "\u001b[K     |████████████████████████████████| 45 kB 2.3 MB/s \n",
            "\u001b[?25hCollecting markdown2==2.3.5\n",
            "  Downloading markdown2-2.3.5.zip (161 kB)\n",
            "\u001b[K     |████████████████████████████████| 161 kB 55.9 MB/s \n",
            "\u001b[?25hCollecting millify==0.1.1\n",
            "  Downloading millify-0.1.1.tar.gz (1.2 kB)\n",
            "Collecting Flask-Bootstrap==3.3.7.1\n",
            "  Downloading Flask-Bootstrap-3.3.7.1.tar.gz (456 kB)\n",
            "\u001b[K     |████████████████████████████████| 456 kB 46.6 MB/s \n",
            "\u001b[?25hCollecting xhtml2pdf==0.2.2\n",
            "  Downloading xhtml2pdf-0.2.2.tar.gz (97 kB)\n",
            "\u001b[K     |████████████████████████████████| 97 kB 5.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: altair==4.1.0 in /usr/local/lib/python3.7/dist-packages (from aequitas==0.42.0->triage) (4.1.0)\n",
            "Collecting Flask==0.12.2\n",
            "  Downloading Flask-0.12.2-py2.py3-none-any.whl (83 kB)\n",
            "\u001b[K     |████████████████████████████████| 83 kB 1.3 MB/s \n",
            "\u001b[?25hCollecting Mako\n",
            "  Downloading Mako-1.1.6-py2.py3-none-any.whl (75 kB)\n",
            "\u001b[K     |████████████████████████████████| 75 kB 3.8 MB/s \n",
            "\u001b[?25hCollecting python-editor>=0.3\n",
            "  Downloading python_editor-1.0.4-py3-none-any.whl (4.9 kB)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from altair==4.1.0->aequitas==0.42.0->triage) (2.11.3)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from altair==4.1.0->aequitas==0.42.0->triage) (2.6.0)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.7/dist-packages (from altair==4.1.0->aequitas==0.42.0->triage) (0.11.2)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from altair==4.1.0->aequitas==0.42.0->triage) (0.3)\n",
            "Collecting plumbum==1.6.4\n",
            "  Downloading plumbum-1.6.4-py2.py3-none-any.whl (110 kB)\n",
            "\u001b[K     |████████████████████████████████| 110 kB 53.1 MB/s \n",
            "\u001b[?25hCollecting argcomplete==1.9.4\n",
            "  Downloading argcomplete-1.9.4-py2.py3-none-any.whl (36 kB)\n",
            "Collecting botocore<1.18.0,>=1.17.45\n",
            "  Downloading botocore-1.17.63-py2.py3-none-any.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 43.7 MB/s \n",
            "\u001b[?25hCollecting s3transfer<0.4.0,>=0.3.0\n",
            "  Downloading s3transfer-0.3.7-py2.py3-none-any.whl (73 kB)\n",
            "\u001b[K     |████████████████████████████████| 73 kB 1.7 MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting humanfriendly>=7.1\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Werkzeug>=0.7 in /usr/local/lib/python3.7/dist-packages (from Flask==0.12.2->aequitas==0.42.0->triage) (1.0.1)\n",
            "Requirement already satisfied: itsdangerous>=0.21 in /usr/local/lib/python3.7/dist-packages (from Flask==0.12.2->aequitas==0.42.0->triage) (1.1.0)\n",
            "Collecting dominate\n",
            "  Downloading dominate-2.6.0-py2.py3-none-any.whl (29 kB)\n",
            "Collecting visitor\n",
            "  Downloading visitor-0.1.3.tar.gz (3.3 kB)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.2.2->triage) (3.0.6)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.2.2->triage) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.2.2->triage) (1.3.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas==1.0.5->triage) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil==2.8.1->triage) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests==2.24.0->triage) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests==2.24.0->triage) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests==2.24.0->triage) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests==2.24.0->triage) (2021.10.8)\n",
            "Collecting fsspec>=0.6.0\n",
            "  Downloading fsspec-2021.11.1-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 69.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.23.1->triage) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.23.1->triage) (3.0.0)\n",
            "Requirement already satisfied: psycopg2 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy-postgres-copy==0.5.0->triage) (2.7.6.1)\n",
            "Requirement already satisfied: html5lib>=1.0 in /usr/local/lib/python3.7/dist-packages (from xhtml2pdf==0.2.2->aequitas==0.42.0->triage) (1.0.1)\n",
            "Requirement already satisfied: httplib2 in /usr/local/lib/python3.7/dist-packages (from xhtml2pdf==0.2.2->aequitas==0.42.0->triage) (0.17.4)\n",
            "Collecting pyPdf2\n",
            "  Downloading PyPDF2-1.26.0.tar.gz (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from xhtml2pdf==0.2.2->aequitas==0.42.0->triage) (7.1.2)\n",
            "Collecting reportlab>=3.0\n",
            "  Downloading reportlab-3.6.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.7 MB 30.0 MB/s \n",
            "\u001b[?25hCollecting docutils<0.16,>=0.10\n",
            "  Downloading docutils-0.15.2-py3-none-any.whl (547 kB)\n",
            "\u001b[K     |████████████████████████████████| 547 kB 41.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from html5lib>=1.0->xhtml2pdf==0.2.2->aequitas==0.42.0->triage) (0.5.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->altair==4.1.0->aequitas==0.42.0->triage) (2.0.1)\n",
            "Building wheels for collected packages: adjustText, alembic, Dickens, Flask-Bootstrap, markdown2, millify, signalled-timeout, tabulate, wrapt, xhtml2pdf, pyPdf2, visitor\n",
            "  Building wheel for adjustText (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for adjustText: filename=adjustText-0.7.3-py3-none-any.whl size=7094 sha256=0cd0a148eec32d7727f0255cf8a7287d89e881dc6ead86aefc0ee9e20972c68e\n",
            "  Stored in directory: /root/.cache/pip/wheels/2f/98/32/afbf902d8f040fadfdf0a44357e4ab750afe165d873bf5893d\n",
            "  Building wheel for alembic (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for alembic: filename=alembic-1.4.2-py2.py3-none-any.whl size=159558 sha256=369a6060203b5af508a6dd935c39ac59abf33b31c186a1e18d27ace4a9570052\n",
            "  Stored in directory: /root/.cache/pip/wheels/4e/b5/00/f93fe1c90b3d501774e91e2e99987f49d16019e40e4bd3afc3\n",
            "  Building wheel for Dickens (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for Dickens: filename=Dickens-1.0.1-py3-none-any.whl size=2643 sha256=eca001de5d3e9e0be78bd5c4e2d3ecdf985ac0053c6fee08106f9ad754453cdf\n",
            "  Stored in directory: /root/.cache/pip/wheels/11/7b/87/87c72b3ffee9c8830070dfc690b0df03833753e2197c7ed230\n",
            "  Building wheel for Flask-Bootstrap (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for Flask-Bootstrap: filename=Flask_Bootstrap-3.3.7.1-py3-none-any.whl size=460124 sha256=68b7e9fdd617deaa23bbf02b88f29db09788bfa7fd73243aa02ee4506a9aecd8\n",
            "  Stored in directory: /root/.cache/pip/wheels/67/a2/d6/50d039c9b59b4caca6d7b53839c8100354a52ab7553d2456eb\n",
            "  Building wheel for markdown2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for markdown2: filename=markdown2-2.3.5-py3-none-any.whl size=33328 sha256=1ddc5176b435b62d1f04e3a3e56c29a2f2e1f56eae9c6f4d5d7bf54b025f2adb\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/b9/ae/4050b5eeeedc7cba8ed5a0203189c89c0fa980f683822bfa31\n",
            "  Building wheel for millify (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for millify: filename=millify-0.1.1-py3-none-any.whl size=1864 sha256=4dfad69872d17937e9e3fae79de90edb40de9412bf2b9ba345d351394ca36a24\n",
            "  Stored in directory: /root/.cache/pip/wheels/38/26/25/c2a8bb99a5cf348903e6ac35a29878e221cc9daeb698545148\n",
            "  Building wheel for signalled-timeout (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for signalled-timeout: filename=signalled_timeout-1.0.0-py3-none-any.whl size=2972 sha256=abc831d64b4047fde192bcc489716143d4262513881d2c562f614b59139ab635\n",
            "  Stored in directory: /root/.cache/pip/wheels/b8/67/0e/f8daac45e46330192ff71cc9c65c86e817df05f7a4a79531d4\n",
            "  Building wheel for tabulate (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tabulate: filename=tabulate-0.8.2-py3-none-any.whl size=23547 sha256=4da872a1d9e3de85bb61bb591e741391c839ac318abe2dedd4670418d6c4160b\n",
            "  Stored in directory: /root/.cache/pip/wheels/33/63/72/4156fe55e8e06830d7aed3d20a6d1aacc753536843ab7330f6\n",
            "  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wrapt: filename=wrapt-1.12.1-cp37-cp37m-linux_x86_64.whl size=68725 sha256=dfe7cfb496e35c190d8c7c52b57eed266d51d8841e5c04fc24c90babd8f7d340\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/76/4c/aa25851149f3f6d9785f6c869387ad82b3fd37582fa8147ac6\n",
            "  Building wheel for xhtml2pdf (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for xhtml2pdf: filename=xhtml2pdf-0.2.2-py3-none-any.whl size=230265 sha256=1fce8ecde170631a8a2ffe22eb0574080031d10156c71dcc65d789d883eebdd7\n",
            "  Stored in directory: /root/.cache/pip/wheels/65/e6/3a/9851102d40dd8e643a4ff3ce5d69988f95d1d9b7448e37a916\n",
            "  Building wheel for pyPdf2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyPdf2: filename=PyPDF2-1.26.0-py3-none-any.whl size=61101 sha256=807fe606910302d128c56fec4cca437cfafbdc397dedd48d8e5da363f9dd2685\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/1a/24/648467ade3a77ed20f35cfd2badd32134e96dd25ca811e64b3\n",
            "  Building wheel for visitor (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for visitor: filename=visitor-0.1.3-py3-none-any.whl size=3943 sha256=001ea18f373f9e221f83490ad58b230077d1441fd4bd2b4cdf998d3e119dcc9f\n",
            "  Stored in directory: /root/.cache/pip/wheels/64/34/11/053f47218984c9a31a00f911ed98dda036b867481dcc527a12\n",
            "Successfully built adjustText alembic Dickens Flask-Bootstrap markdown2 millify signalled-timeout tabulate wrapt xhtml2pdf pyPdf2 visitor\n",
            "Installing collected packages: python-dateutil, numpy, jmespath, docutils, visitor, scipy, reportlab, pyPdf2, pandas, Flask, dominate, botocore, xhtml2pdf, tabulate, SQLAlchemy, seaborn, s3transfer, PyYAML, python-editor, plumbum, ohio, millify, markdown2, Mako, humanfriendly, fsspec, Flask-Bootstrap, Dickens, argcomplete, wrapt, verboselogs, sqlalchemy-postgres-copy, signalled-timeout, scikit-learn, s3fs, requests, psycopg2-binary, pebble, inflection, graphviz, coloredlogs, boto3, argcmdr, alembic, aequitas, adjustText, triage\n",
            "  Attempting uninstall: python-dateutil\n",
            "    Found existing installation: python-dateutil 2.8.2\n",
            "    Uninstalling python-dateutil-2.8.2:\n",
            "      Successfully uninstalled python-dateutil-2.8.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "  Attempting uninstall: docutils\n",
            "    Found existing installation: docutils 0.17.1\n",
            "    Uninstalling docutils-0.17.1:\n",
            "      Successfully uninstalled docutils-0.17.1\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.1.5\n",
            "    Uninstalling pandas-1.1.5:\n",
            "      Successfully uninstalled pandas-1.1.5\n",
            "  Attempting uninstall: Flask\n",
            "    Found existing installation: Flask 1.1.4\n",
            "    Uninstalling Flask-1.1.4:\n",
            "      Successfully uninstalled Flask-1.1.4\n",
            "  Attempting uninstall: tabulate\n",
            "    Found existing installation: tabulate 0.8.9\n",
            "    Uninstalling tabulate-0.8.9:\n",
            "      Successfully uninstalled tabulate-0.8.9\n",
            "  Attempting uninstall: SQLAlchemy\n",
            "    Found existing installation: SQLAlchemy 1.4.27\n",
            "    Uninstalling SQLAlchemy-1.4.27:\n",
            "      Successfully uninstalled SQLAlchemy-1.4.27\n",
            "  Attempting uninstall: seaborn\n",
            "    Found existing installation: seaborn 0.11.2\n",
            "    Uninstalling seaborn-0.11.2:\n",
            "      Successfully uninstalled seaborn-0.11.2\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: argcomplete\n",
            "    Found existing installation: argcomplete 1.12.3\n",
            "    Uninstalling argcomplete-1.12.3:\n",
            "      Successfully uninstalled argcomplete-1.12.3\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.13.3\n",
            "    Uninstalling wrapt-1.13.3:\n",
            "      Successfully uninstalled wrapt-1.13.3\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.0.1\n",
            "    Uninstalling scikit-learn-1.0.1:\n",
            "      Successfully uninstalled scikit-learn-1.0.1\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: graphviz\n",
            "    Found existing installation: graphviz 0.10.1\n",
            "    Uninstalling graphviz-0.10.1:\n",
            "      Successfully uninstalled graphviz-0.10.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.3.post1 requires numpy<1.20,>=1.16.0, but you have numpy 1.21.1 which is incompatible.\n",
            "imbalanced-learn 0.8.1 requires scikit-learn>=0.24, but you have scikit-learn 0.23.1 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas~=1.1.0; python_version >= \"3.0\", but you have pandas 1.0.5 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.24.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed Dickens-1.0.1 Flask-0.12.2 Flask-Bootstrap-3.3.7.1 Mako-1.1.6 PyYAML-5.4.1 SQLAlchemy-1.3.18 adjustText-0.7.3 aequitas-0.42.0 alembic-1.4.2 argcmdr-0.7.0 argcomplete-1.9.4 boto3-1.14.45 botocore-1.17.63 coloredlogs-14.0 docutils-0.15.2 dominate-2.6.0 fsspec-2021.11.1 graphviz-0.14 humanfriendly-10.0 inflection-0.5.0 jmespath-0.10.0 markdown2-2.3.5 millify-0.1.1 numpy-1.21.1 ohio-0.5.0 pandas-1.0.5 pebble-4.5.3 plumbum-1.6.4 psycopg2-binary-2.8.5 pyPdf2-1.26.0 python-dateutil-2.8.1 python-editor-1.0.4 reportlab-3.6.3 requests-2.24.0 s3fs-0.4.2 s3transfer-0.3.7 scikit-learn-0.23.1 scipy-1.5.0 seaborn-0.10.1 signalled-timeout-1.0.0 sqlalchemy-postgres-copy-0.5.0 tabulate-0.8.2 triage-5.1.0 verboselogs-1.7 visitor-0.1.3 wrapt-1.12.1 xhtml2pdf-0.2.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "dateutil",
                  "numpy",
                  "pandas"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mQ1nY6lksXD"
      },
      "source": [
        "🛑  &nbsp;&nbsp;**NOTE: Before continuing, your colab runtime may need to be restarted for the installed packages to take effect. If a \"Restart Runtime\" button appeared at the bottom of the output above, be sure to click it before moving on to the next section!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "reskRriKlcpO"
      },
      "source": [
        "## A Quick Look at the DonorsChoose Data\n",
        "\n",
        "Before getting into triage, let's just take a quick look at the data we'll be using here. To get started, we'll need to connect to the database we just created..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvDxGoeCmSKQ"
      },
      "source": [
        "from sqlalchemy.engine.url import URL\n",
        "from triage.util.db import create_engine\n",
        "import pandas as pd\n",
        "\n",
        "db_url = URL(\n",
        "            'postgres',\n",
        "            host='localhost',\n",
        "            username='postgres',\n",
        "            database='donors_choose',\n",
        "            password='postgres',\n",
        "            port=5432,\n",
        "        )\n",
        "\n",
        "db_engine = create_engine(db_url)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfgHR1NfnMI4"
      },
      "source": [
        "The DonorsChoose dataset contains four main tables we'll need here:\n",
        "- **Projects** contains information about each project as well as some details about the teacher posting it and their school and district\n",
        "- **Essays** contains the detailed descriptions that the teacher post describing their project and needs\n",
        "- **Resources** contains detailed information about the specific number, type, and cost of resources being asked for in the project\n",
        "- **Donations** contains information about the donations received by each project on a transactional level, as well as some details about the donor\n",
        "\n",
        "Let's take a look at the projects:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "dhElc5PMprk0",
        "outputId": "76f941ae-2b13-424f-d842-61a469fccb2c"
      },
      "source": [
        "pd.read_sql('SELECT COUNT(*) FROM data.projects', db_engine)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>16480</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   count\n",
              "0  16480"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "HkrUfqnmqs0m",
        "outputId": "8a1131c8-a5a0-4eda-cf3d-f4717707cf82"
      },
      "source": [
        "pd.read_sql('SELECT * FROM data.projects LIMIT 5', db_engine)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>schoolid</th>\n",
              "      <th>projectid_str</th>\n",
              "      <th>teacher_acctid</th>\n",
              "      <th>school_ncesid</th>\n",
              "      <th>school_latitude</th>\n",
              "      <th>school_longitude</th>\n",
              "      <th>school_city</th>\n",
              "      <th>school_state</th>\n",
              "      <th>school_zip</th>\n",
              "      <th>school_metro</th>\n",
              "      <th>school_district</th>\n",
              "      <th>school_county</th>\n",
              "      <th>school_charter</th>\n",
              "      <th>school_magnet</th>\n",
              "      <th>school_year_round</th>\n",
              "      <th>school_nlns</th>\n",
              "      <th>school_kipp</th>\n",
              "      <th>school_charter_ready_promise</th>\n",
              "      <th>teacher_prefix</th>\n",
              "      <th>teacher_teach_for_america</th>\n",
              "      <th>teacher_ny_teaching_fellow</th>\n",
              "      <th>primary_focus_subject</th>\n",
              "      <th>primary_focus_area</th>\n",
              "      <th>secondary_focus_subject</th>\n",
              "      <th>secondary_focus_area</th>\n",
              "      <th>resource_type</th>\n",
              "      <th>poverty_level</th>\n",
              "      <th>grade_level</th>\n",
              "      <th>fulfillment_labor_materials</th>\n",
              "      <th>total_asking_price</th>\n",
              "      <th>total_price_including_optional_support</th>\n",
              "      <th>students_reached</th>\n",
              "      <th>eligible_double_your_impact_match</th>\n",
              "      <th>eligible_almost_home_match</th>\n",
              "      <th>date_posted</th>\n",
              "      <th>entity_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>29a2da790e38b6c8a1c70aced6b9c765</td>\n",
              "      <td>30c034618e67d00c641f9b5b7775c0f4</td>\n",
              "      <td>0903da60e148adc6280d55f5d94791a5</td>\n",
              "      <td>192013001182</td>\n",
              "      <td>41.428391</td>\n",
              "      <td>-91.049135</td>\n",
              "      <td>Muscatine</td>\n",
              "      <td>IA</td>\n",
              "      <td>52761</td>\n",
              "      <td>None</td>\n",
              "      <td>Muscatine Cmty School District</td>\n",
              "      <td>Muscatine</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>Ms.</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>Applied Sciences</td>\n",
              "      <td>Math &amp; Science</td>\n",
              "      <td>College &amp; Career Prep</td>\n",
              "      <td>Applied Learning</td>\n",
              "      <td>Supplies</td>\n",
              "      <td>high poverty</td>\n",
              "      <td>Grades 6-8</td>\n",
              "      <td>35.0</td>\n",
              "      <td>511.32</td>\n",
              "      <td>601.55</td>\n",
              "      <td>100</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>2012-08-06</td>\n",
              "      <td>234148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>06ef48acbdf9b013d4bc4bfc8d328cc1</td>\n",
              "      <td>94199c544d9d2926c1820e5c6cde1eb6</td>\n",
              "      <td>fb340c7ac3b22a5984c6a82602e4a510</td>\n",
              "      <td>450111000143</td>\n",
              "      <td>32.233070</td>\n",
              "      <td>-80.855905</td>\n",
              "      <td>Bluffton</td>\n",
              "      <td>SC</td>\n",
              "      <td>29910</td>\n",
              "      <td>rural</td>\n",
              "      <td>Beaufort Co School District</td>\n",
              "      <td>Beaufort</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>Ms.</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>Literacy</td>\n",
              "      <td>Literacy &amp; Language</td>\n",
              "      <td>ESL</td>\n",
              "      <td>Literacy &amp; Language</td>\n",
              "      <td>Supplies</td>\n",
              "      <td>high poverty</td>\n",
              "      <td>Grades 3-5</td>\n",
              "      <td>35.0</td>\n",
              "      <td>167.43</td>\n",
              "      <td>192.45</td>\n",
              "      <td>40</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>2010-07-10</td>\n",
              "      <td>453579</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>06ef48acbdf9b013d4bc4bfc8d328cc1</td>\n",
              "      <td>61f42f174afef1ed2419ab948a647137</td>\n",
              "      <td>fb340c7ac3b22a5984c6a82602e4a510</td>\n",
              "      <td>450111000143</td>\n",
              "      <td>32.233070</td>\n",
              "      <td>-80.855905</td>\n",
              "      <td>Bluffton</td>\n",
              "      <td>SC</td>\n",
              "      <td>29910</td>\n",
              "      <td>rural</td>\n",
              "      <td>Beaufort Co School District</td>\n",
              "      <td>Beaufort</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>Ms.</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>Literacy</td>\n",
              "      <td>Literacy &amp; Language</td>\n",
              "      <td>Applied Sciences</td>\n",
              "      <td>Math &amp; Science</td>\n",
              "      <td>Other</td>\n",
              "      <td>high poverty</td>\n",
              "      <td>Grades 3-5</td>\n",
              "      <td>35.0</td>\n",
              "      <td>167.43</td>\n",
              "      <td>196.98</td>\n",
              "      <td>45</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>2011-06-09</td>\n",
              "      <td>353855</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>06ef48acbdf9b013d4bc4bfc8d328cc1</td>\n",
              "      <td>c966f5226f42aaaf6b115d7dbaefdea3</td>\n",
              "      <td>e0b5a72f41a376b28db9c2e838a24de5</td>\n",
              "      <td>450111000143</td>\n",
              "      <td>32.233070</td>\n",
              "      <td>-80.855905</td>\n",
              "      <td>Bluffton</td>\n",
              "      <td>SC</td>\n",
              "      <td>29910</td>\n",
              "      <td>rural</td>\n",
              "      <td>Beaufort Co School District</td>\n",
              "      <td>Beaufort</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>Mrs.</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>Literacy</td>\n",
              "      <td>Literacy &amp; Language</td>\n",
              "      <td>Health &amp; Life Science</td>\n",
              "      <td>Math &amp; Science</td>\n",
              "      <td>Other</td>\n",
              "      <td>high poverty</td>\n",
              "      <td>Grades 3-5</td>\n",
              "      <td>35.0</td>\n",
              "      <td>162.14</td>\n",
              "      <td>190.75</td>\n",
              "      <td>25</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>2011-06-13</td>\n",
              "      <td>353178</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>06ef48acbdf9b013d4bc4bfc8d328cc1</td>\n",
              "      <td>69e9c24111daa1e6ba64c6d5538e4df1</td>\n",
              "      <td>32e86c49396707f71fdc0398ab2b844b</td>\n",
              "      <td>450111000143</td>\n",
              "      <td>32.233070</td>\n",
              "      <td>-80.855905</td>\n",
              "      <td>Bluffton</td>\n",
              "      <td>SC</td>\n",
              "      <td>29910</td>\n",
              "      <td>rural</td>\n",
              "      <td>Beaufort Co School District</td>\n",
              "      <td>Beaufort</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>Mrs.</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>History &amp; Geography</td>\n",
              "      <td>History &amp; Civics</td>\n",
              "      <td>Environmental Science</td>\n",
              "      <td>Math &amp; Science</td>\n",
              "      <td>Books</td>\n",
              "      <td>high poverty</td>\n",
              "      <td>Grades 3-5</td>\n",
              "      <td>35.0</td>\n",
              "      <td>381.27</td>\n",
              "      <td>448.55</td>\n",
              "      <td>25</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>2012-07-15</td>\n",
              "      <td>239363</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                           schoolid  ... entity_id\n",
              "0  29a2da790e38b6c8a1c70aced6b9c765  ...    234148\n",
              "1  06ef48acbdf9b013d4bc4bfc8d328cc1  ...    453579\n",
              "2  06ef48acbdf9b013d4bc4bfc8d328cc1  ...    353855\n",
              "3  06ef48acbdf9b013d4bc4bfc8d328cc1  ...    353178\n",
              "4  06ef48acbdf9b013d4bc4bfc8d328cc1  ...    239363\n",
              "\n",
              "[5 rows x 36 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Knvi1ZB8rANB"
      },
      "source": [
        "Note that the `projectid_str` column can be used to link out to the other tables. For instance, let's look at what we can find out about project `30c034618e67d00c641f9b5b7775c0f4`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "id": "eNl81xoErL7g",
        "outputId": "108bc57e-6ef5-4d60-94e8-1c03be90a95f"
      },
      "source": [
        "pd.read_sql(\"SELECT * FROM data.essays WHERE projectid_str='30c034618e67d00c641f9b5b7775c0f4'\", db_engine)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>projectid_str</th>\n",
              "      <th>teacher_acctid</th>\n",
              "      <th>title</th>\n",
              "      <th>short_description</th>\n",
              "      <th>need_statement</th>\n",
              "      <th>essay</th>\n",
              "      <th>entity_id</th>\n",
              "      <th>date_posted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>30c034618e67d00c641f9b5b7775c0f4</td>\n",
              "      <td>0903da60e148adc6280d55f5d94791a5</td>\n",
              "      <td>Illuminate Your Future</td>\n",
              "      <td>Can you imagine what the future will bring wit...</td>\n",
              "      <td>My students need LED bulbs and electronic comp...</td>\n",
              "      <td>Can you imagine what the future will bring wit...</td>\n",
              "      <td>234148</td>\n",
              "      <td>2012-08-06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      projectid_str  ... date_posted\n",
              "0  30c034618e67d00c641f9b5b7775c0f4  ...  2012-08-06\n",
              "\n",
              "[1 rows x 8 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "PdLzQlGXraVX",
        "outputId": "1f52caa9-1068-434f-a3e0-dfb997d25935"
      },
      "source": [
        "pd.read_sql(\"\"\"\n",
        "  SELECT project_resource_type,\n",
        "        COUNT(*) AS num_distinct_resources, \n",
        "        SUM(item_quantity) AS num_total_resources,\n",
        "        AVG(item_unit_price) AS avg_price,\n",
        "        SUM(item_unit_price * item_quantity) AS total_cost\n",
        "  FROM data.resources \n",
        "  WHERE projectid_str='30c034618e67d00c641f9b5b7775c0f4'\n",
        "  GROUP BY 1;\n",
        "  \"\"\", db_engine)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>project_resource_type</th>\n",
              "      <th>num_distinct_resources</th>\n",
              "      <th>num_total_resources</th>\n",
              "      <th>avg_price</th>\n",
              "      <th>total_cost</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Supplies</td>\n",
              "      <td>7</td>\n",
              "      <td>113.0</td>\n",
              "      <td>13.004286</td>\n",
              "      <td>400.19</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  project_resource_type  num_distinct_resources  ...  avg_price  total_cost\n",
              "0              Supplies                       7  ...  13.004286      400.19\n",
              "\n",
              "[1 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "lAhWr6FJ9656",
        "outputId": "2785378b-6263-4d4f-d879-816279458c03"
      },
      "source": [
        "pd.read_sql(\"\"\"\n",
        "  SELECT \n",
        "    COUNT(*) AS num_donations,\n",
        "    SUM(donation_to_project) AS total_donation,\n",
        "    SUM(CASE WHEN is_teacher_acct THEN 1 ELSE 0 END) AS num_teacher_donation\n",
        "  FROM data.donations \n",
        "  WHERE projectid_str='30c034618e67d00c641f9b5b7775c0f4'\n",
        "  ;\n",
        "  \"\"\", db_engine)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num_donations</th>\n",
              "      <th>total_donation</th>\n",
              "      <th>num_teacher_donation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>511.32</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   num_donations  total_donation  num_teacher_donation\n",
              "0              1          511.32                     0"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIj8GvQF_1cV"
      },
      "source": [
        "## Formulating the project\n",
        "\n",
        "Now that we're familiar with the available data, let's turn to the prediction problem at hand. Because reviewing and offering suggestions to posted projects will be time and resource-intensive, we might assume that DonorsChoose can only help a fraction of all projects that get posted, let's suppose 10%. Then, we might formulate our problem along the lines of:\n",
        "\n",
        "**Each day, for all the projects posted on that day, can we identify the 10% of projects with the highest risk of not being fully funded within 4 months to prioritize for review by digital content experts.**\n",
        "\n",
        "With this formulation in mind, we can define a cohort and label for our analysis. `triage` will allow us to define these directly as a SQL query, so let's start there..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6A7_a1SADxE9"
      },
      "source": [
        "### Defining the Cohort\n",
        "\n",
        "Because most models to inform important decisions will need to generalize into the future, `triage` focuses on respecting the temporal nature of the data (discussed in more detail below). The `cohort` is the set of relevant entities for model training/prediction at a given point in time, which `triage` referrs to as an `as_of_date`.\n",
        "\n",
        "🚧 &nbsp;&nbsp;NOTE: In `triage`, an `as_of_date` is taken to be midnight at the **beginning** of that date.\n",
        "\n",
        "Here, the cohort is relatively straightforward: we simply want to identify all of the projects that were posted, right on the day of posting. Although we were looking at the identifier `projectid_str` above, `triage` looks for a column called `entity_id` to uniquely identify entities to its models. We've already added this column to this dataset, so we'll use that below.\n",
        "\n",
        "🚧 &nbsp;&nbsp;NOTE: `triage` expects entities in the data to be identified by an **integer column** called `entity_id`.\n",
        "\n",
        "With those details in mind, let's look at an example of how we might define the cohort from our data for this project:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "Fq5W82jLLwQF",
        "outputId": "c66b78a4-fade-4a1d-8886-4df0fee7ba62"
      },
      "source": [
        "example_as_of_date = '2012-08-07'\n",
        "\n",
        "pd.read_sql(\"\"\"\n",
        "      SELECT distinct(entity_id)\n",
        "      FROM data.projects\n",
        "      WHERE date_posted = '{as_of_date}'::date - interval '1day'\n",
        "  ;\n",
        "  \"\"\".format(as_of_date=example_as_of_date), db_engine)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>entity_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>234035</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>234148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>234234</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   entity_id\n",
              "0     234035\n",
              "1     234148\n",
              "2     234234"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qiDh3DdOMrGp"
      },
      "source": [
        "In `triage` we'll be able to use `{as_of_date}` as a placeholder for time just as we're doing here.\n",
        "\n",
        "Also note that because the `as_of_date` is taken to be midnight, we're looking at the projects posted the previous day (hence subtracting the 1 day interval in the query).\n",
        "\n",
        "For `triage`, we use a yaml format for configuration (described further below) and we'll be able to provide this query directly:\n",
        "```\n",
        "cohort_config:\n",
        "  query: |\n",
        "    SELECT distinct(entity_id)\n",
        "      FROM data.projects\n",
        "    WHERE date_posted = '{as_of_date}'::date - interval '1day'\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tv-YbkWuOFnI"
      },
      "source": [
        "### Defining the Label\n",
        "\n",
        "For modeling, we also need to consider the outcome we care about. Returning to our formulation, we described trying to identify projects which will not be fully funded within the four months they are active on the platform.\n",
        "\n",
        "As with the cohort, notice that labels are calculated relative to a given point in time (the `as_of_date` described above) and over a specific time horizon (here, 4 months from posting). In triage, this time horizon is referred to as a `label_timespan` and is also available as a parameter to your label definition, again specified as a query:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "Odpo6nluPGLk",
        "outputId": "3eb18c39-f7df-49d3-80f2-3ed1c72b9ef6"
      },
      "source": [
        "example_as_of_date = '2012-08-07'\n",
        "example_label_timespan = '4month'\n",
        "\n",
        "pd.read_sql(\"\"\"\n",
        "    WITH cohort_query AS (\n",
        "      SELECT distinct(entity_id)\n",
        "      FROM data.projects\n",
        "      WHERE date_posted = '{as_of_date}'::date - interval '1day'\n",
        "    )\n",
        "    , cohort_donations AS (\n",
        "      SELECT \n",
        "        c.entity_id, \n",
        "        COALESCE(SUM(d.donation_to_project), 0) AS total_donation\n",
        "      FROM cohort_query c\n",
        "      LEFT JOIN data.donations d \n",
        "        ON c.entity_id = d.entity_id\n",
        "        AND d.donation_timestamp \n",
        "          BETWEEN '{as_of_date}'::date - interval '1day'\n",
        "          AND '{as_of_date}'::date + interval '{label_timespan}'\n",
        "      GROUP BY 1\n",
        "    )\n",
        "    SELECT c.entity_id,\n",
        "    CASE \n",
        "      WHEN COALESCE(d.total_donation, 0) >= p.total_asking_price THEN 0\n",
        "      ELSE 1\n",
        "    END AS outcome  \n",
        "    FROM cohort_query c\n",
        "    JOIN data.projects p USING(entity_id)\n",
        "    LEFT JOIN cohort_donations d using(entity_id)\n",
        "  ;\n",
        "  \"\"\".format(as_of_date=example_as_of_date, label_timespan=example_label_timespan), db_engine)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>entity_id</th>\n",
              "      <th>outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>234035</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>234148</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>234234</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   entity_id  outcome\n",
              "0     234035        1\n",
              "1     234148        0\n",
              "2     234234        0"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MLeE7N-NSWam"
      },
      "source": [
        "A little more complicated than our cohort query, but still reasonably straightforward: we start with the cohort defined above, then find all the donations to those projects within the label timespan (e.g., the following 4 months after posting), and finally compare that to the total price of the project to create a binary classification label for whether or not the project was fully funded.\n",
        "\n",
        "Notice here that because we will intervene on projects at risk for **NOT** being fully funded, we define this as our class 1 label while those that do reach their funding goal are given class 0.\n",
        "\n",
        "As with the cohort, we'll be able to specify this label query directly to triage in our yaml configuation:\n",
        "```\n",
        "label_config:\n",
        "  query: |\n",
        "    WITH cohort_query AS (\n",
        "      SELECT distinct(entity_id)\n",
        "      FROM data.projects\n",
        "      WHERE date_posted = '{as_of_date}'::date - interval '1day'\n",
        "    )\n",
        "    , cohort_donations AS (\n",
        "      SELECT \n",
        "        c.entity_id, \n",
        "        COALESCE(SUM(d.donation_to_project), 0) AS total_donation\n",
        "      FROM cohort_query c\n",
        "      LEFT JOIN data.donations d \n",
        "        ON c.entity_id = d.entity_id\n",
        "        AND d.donation_timestamp \n",
        "          BETWEEN '{as_of_date}'::date - interval '1day'\n",
        "          AND '{as_of_date}'::date + interval '{label_timespan}'\n",
        "      GROUP BY 1\n",
        "    )\n",
        "    SELECT c.entity_id,\n",
        "    CASE \n",
        "      WHEN COALESCE(d.total_donation, 0) >= p.total_asking_price THEN 0\n",
        "      ELSE 1\n",
        "    END AS outcome  \n",
        "    FROM cohort_query c\n",
        "    JOIN data.projects p USING(entity_id)\n",
        "    LEFT JOIN cohort_donations d using(entity_id)\n",
        "\n",
        "  name: 'fully_funded'\n",
        "```\n",
        "\n",
        "For more details these two pieces of the modeling pipeline, see the [cohort and label deep dive in the triage docs](https://dssg.github.io/triage/experiments/cohort-labels/). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3RTN8p6VWQ8z"
      },
      "source": [
        "### Dealing with Time\n",
        "\n",
        "As noted above, `triage` is designed for problems where the desire to generalize to future data and therefore is careful to respect the temporal nature of the problem. This is particularly salient in two places: defining the validation strategy for model evaluation and ensuring that features only make use of information available at the time of analysis/prediction.\n",
        "\n",
        "For validation, the idea is generally simple: models should be trained on historical data and validated on future data. As such, `triage` constructs validation splits that reflect this process by using a certain point in time as the cut-off between training and validation and then moving this cut-off back through the data to generate multiple splits. The implementation is a bit more complicated and relies on several parameters, the details of which we won't go deep into here, but you can find a much deeper discussion in the [longer \"dirty duck\" tutorial](https://dssg.github.io/triage/dirtyduck/triage_intro/) as well as in the [experiment config docs](https://dssg.github.io/triage/experiments/experiment-config/).\n",
        "\n",
        "![temporal figure](https://dssg.github.io/triage/experiments/temporal_config_graph.png)\n",
        "\n",
        "In short, these parameters are (illustrated across three training/validation splits in the figure above):\n",
        "- feature start/end times: what range of history is feature information available for?\n",
        "- label start/end times: what range of history is outcome (label) data available for?\n",
        "- model update frequency: what is the interval between refreshes of the model?\n",
        "- test durations: over what time period will the model be in use for making predictions?\n",
        "- max training history: how much historical data should be used for model training (that is, for rows/examples)?\n",
        "- training/test as_of_date frequencies: within a training or validation (test) set, how frequently should cohorts be sampled?\n",
        "- training/test label timespans: over what time horizon are labels (outcomes) collected?\n",
        "\n",
        "As with the cohorts and labels, these parameters are specified to `triage` via its yaml configuration file. Here's what this will look like for our setting:\n",
        "```\n",
        "temporal_config:\n",
        "\n",
        "    # first date our feature data is good\n",
        "    feature_start_time: '2000-01-01'\n",
        "    feature_end_time: '2013-06-01'\n",
        "\n",
        "    # first date our label data is good\n",
        "    # donorschoose: as far back as we have good donation data\n",
        "    label_start_time: '2011-09-02'\n",
        "    label_end_time: '2013-06-01'\n",
        "\n",
        "    model_update_frequency: '4month'\n",
        "\n",
        "    # length of time defining a test set\n",
        "    test_durations: ['3month']\n",
        "    # defines how far back a training set reaches\n",
        "    max_training_histories: ['1y']\n",
        "\n",
        "    # we sample every day, since new projects are posted\n",
        "    # every day\n",
        "    training_as_of_date_frequencies: ['1day']\n",
        "    test_as_of_date_frequencies: ['1day']\n",
        "    \n",
        "    # when posted project timeout\n",
        "    label_timespans: ['3month']\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQtPjBJUaaVJ"
      },
      "source": [
        "### Model Evaluation Metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cY_UC4Taey9"
      },
      "source": [
        "### Defining Features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0YNaIVySaj2Z"
      },
      "source": [
        "### Model and Hyperparameter Grid"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XX-inX6o7QBE"
      },
      "source": [
        "## experiment_config.yaml"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdDjQCovS1GG"
      },
      "source": [
        "config_yaml = \"\"\"\n",
        "config_version: 'v7'\n",
        "\n",
        "model_comment: 'triage demo'\n",
        "\n",
        "random_seed: 1995\n",
        "\n",
        "temporal_config:\n",
        "\n",
        "    # first date our feature data is good\n",
        "    feature_start_time: '2000-01-01'\n",
        "    feature_end_time: '2013-06-01'\n",
        "\n",
        "    # first date our label data is good\n",
        "    # donorschoose: as far back as we have good donation data\n",
        "    label_start_time: '2011-09-02'\n",
        "    label_end_time: '2013-06-01'\n",
        "\n",
        "    model_update_frequency: '4month'\n",
        "\n",
        "    # length of time defining a test set\n",
        "    test_durations: ['3month']\n",
        "    # defines how far back a training set reaches\n",
        "    max_training_histories: ['1y']\n",
        "\n",
        "    # we sample every day, since new projects are posted\n",
        "    # every day\n",
        "    training_as_of_date_frequencies: ['1day']\n",
        "    test_as_of_date_frequencies: ['1day']\n",
        "    \n",
        "    # when posted project timeout\n",
        "    label_timespans: ['3month']\n",
        "    \n",
        "\n",
        "cohort_config:\n",
        "  query: |\n",
        "    SELECT distinct(entity_id)\n",
        "      FROM data.projects\n",
        "    WHERE date_posted = '{as_of_date}'::date - interval '1day'\n",
        "\n",
        "label_config:\n",
        "  query: |\n",
        "    WITH cohort_query AS (\n",
        "      SELECT distinct(entity_id)\n",
        "      FROM data.projects\n",
        "      WHERE date_posted = '{as_of_date}'::date - interval '1day'\n",
        "    )\n",
        "    , cohort_donations AS (\n",
        "      SELECT \n",
        "        c.entity_id, \n",
        "        COALESCE(SUM(d.donation_to_project), 0) AS total_donation\n",
        "      FROM cohort_query c\n",
        "      LEFT JOIN data.donations d \n",
        "        ON c.entity_id = d.entity_id\n",
        "        AND d.donation_timestamp \n",
        "          BETWEEN '{as_of_date}'::date - interval '1day'\n",
        "          AND '{as_of_date}'::date + interval '{label_timespan}'\n",
        "      GROUP BY 1\n",
        "    )\n",
        "    SELECT c.entity_id,\n",
        "    CASE \n",
        "      WHEN COALESCE(d.total_donation, 0) >= p.total_asking_price THEN 0\n",
        "      ELSE 1\n",
        "    END AS outcome  \n",
        "    FROM cohort_query c\n",
        "    JOIN data.projects p USING(entity_id)\n",
        "    LEFT JOIN cohort_donations d using(entity_id)\n",
        "\n",
        "  name: 'fully_funded'\n",
        "\n",
        "\n",
        "feature_aggregations:\n",
        "  -\n",
        "    prefix: 'project_features'\n",
        "    from_obj: 'data.projects'\n",
        "    knowledge_date_column: 'date_posted'\n",
        "\n",
        "    aggregates_imputation:\n",
        "      all:\n",
        "        type: 'zero'\n",
        "\n",
        "    categoricals_imputation:\n",
        "      all:\n",
        "        type: 'null_category'          \n",
        "\n",
        "    categoricals:\n",
        "      -\n",
        "        column: 'resource_type'\n",
        "        metrics:\n",
        "          - 'max' \n",
        "        choice_query: 'select distinct resource_type from data.projects'\n",
        "    \n",
        "    aggregates:\n",
        "      -\n",
        "        quantity: 'total_asking_price'\n",
        "        metrics:\n",
        "          - 'sum'\n",
        "      \n",
        "    # Since our time-aggregate features are precomputed, feature interval is \n",
        "    # irrelvant. We keep 'all' as a default.\n",
        "    intervals: ['all'] \n",
        "    groups: ['entity_id']\n",
        "\n",
        "grid_config:\n",
        "    'sklearn.ensemble.RandomForestClassifier':\n",
        "      n_estimators: [150]\n",
        "      max_depth: [50]\n",
        "      min_samples_split: [25]\n",
        "    \n",
        "    'sklearn.tree.DecisionTreeClassifier':\n",
        "      max_depth: [3]\n",
        "      max_features: [null]\n",
        "      min_samples_split: [25]\n",
        "      \n",
        "    'triage.component.catwalk.estimators.classifiers.ScaledLogisticRegression':\n",
        "        C: [0.1]\n",
        "        penalty: ['l1']\n",
        "    \n",
        "    'triage.component.catwalk.baselines.rankers.PercentileRankOneFeature':\n",
        "      feature: ['project_features_entity_id_all_total_asking_price_sum']\n",
        "      descend: [False]\n",
        "\n",
        "\n",
        "scoring:\n",
        "    testing_metric_groups:\n",
        "        -\n",
        "          metrics: [precision@, recall@]\n",
        "          thresholds:\n",
        "              percentiles: [1, 2, 3, 4, 5, 6, 7, 8, 9, \n",
        "                  10, 11, 12, 13, 14, 15, 16, 17, 18, 19,\n",
        "                  20, 21, 22, 23, 24, 25, 26, 27, 28, 29, \n",
        "                  30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n",
        "                  40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n",
        "                  50, 51, 52, 53, 54, 55, 56, 57, 58, 59,\n",
        "                  60, 61, 62, 63, 64, 65, 66, 67, 68, 69,\n",
        "                  70, 71, 72, 73, 74, 75, 76, 77, 78, 79,\n",
        "                  80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n",
        "                  90, 91, 92, 93, 94, 95, 96, 97, 98, 99,\n",
        "                  100]\n",
        "              top_n: [25, 50, 100]\n",
        "\n",
        "    training_metric_groups:\n",
        "        -\n",
        "          metrics: [precision@, recall@]\n",
        "          thresholds:\n",
        "              percentiles: [1, 2, 3, 4, 5, 6, 7, 8, 9, \n",
        "                  10, 11, 12, 13, 14, 15, 16, 17, 18, 19,\n",
        "                  20, 21, 22, 23, 24, 25, 26, 27, 28, 29, \n",
        "                  30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n",
        "                  40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n",
        "                  50, 51, 52, 53, 54, 55, 56, 57, 58, 59,\n",
        "                  60, 61, 62, 63, 64, 65, 66, 67, 68, 69,\n",
        "                  70, 71, 72, 73, 74, 75, 76, 77, 78, 79,\n",
        "                  80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n",
        "                  90, 91, 92, 93, 94, 95, 96, 97, 98, 99,\n",
        "                  100]\n",
        "              top_n: [25, 50, 100]\n",
        "          \n",
        "bias_audit_config:\n",
        "    from_obj_table: 'data.projects'\n",
        "    attribute_columns:\n",
        "      - 'teacher_prefix'\n",
        "    knowledge_date_column: 'date_posted'\n",
        "    entity_id_column: 'entity_id'\n",
        "    ref_groups_method: 'predefined'\n",
        "    ref_groups:\n",
        "        'teacher_prefix': 'Mr.'\n",
        "    thresholds:\n",
        "        percentiles: [5, 10, 15, 20, 25, 50, 100]\n",
        "        top_n: [25, 50, 100]\n",
        "\n",
        "individual_importance:\n",
        "    methods: [] # empty list means don't calculate individual importances\n",
        "    n_ranks: 1 \n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qcqeRvUT7V1D"
      },
      "source": [
        "## database.yaml"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3i88ZFQupfp6"
      },
      "source": [
        "database_yaml = \"\"\"\n",
        "host: localhost\n",
        "user: postgres\n",
        "db: donors_choose\n",
        "pass: postgres\n",
        "port: 5432\n",
        "role: postgres\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHR9wnAw7d__"
      },
      "source": [
        "## run.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYzBKFG3qDhQ",
        "outputId": "c298acbf-bc4f-417e-ebf6-81752395bad2"
      },
      "source": [
        "import yaml\n",
        "\n",
        "from sqlalchemy.engine.url import URL\n",
        "from triage.util.db import create_engine\n",
        "from triage.experiments import MultiCoreExperiment\n",
        "import logging\n",
        "\n",
        "import os\n",
        "\n",
        "from sqlalchemy.event import listens_for\n",
        "from sqlalchemy.pool import Pool\n",
        "\n",
        "def run_triage():\n",
        "\n",
        "  # andrew_id = os.getenv('USER')\n",
        "  # user_path = os.path.join('/data/users/', andrew_id)\n",
        "  user_path = '/content'\n",
        "\n",
        "  # add logging to a file (it will also go to stdout via triage logging config)\n",
        "  log_filename = os.path.join(user_path, 'triage.log')\n",
        "  logger = logging.getLogger('')\n",
        "  hdlr = logging.FileHandler(log_filename)\n",
        "  hdlr.setLevel(15)   # verbose level\n",
        "  hdlr.setFormatter(logging.Formatter('%(name)-30s  %(asctime)s %(levelname)10s %(process)6d  %(filename)-24s  %(lineno)4d: %(message)s', '%d/%m/%Y %I:%M:%S %p'))\n",
        "  logger.addHandler(hdlr)\n",
        "\n",
        "  # creating database engine\n",
        "  # dbfile = os.path.join(user_path, 'database.yaml')\n",
        "\n",
        "  # with open(dbfile, 'r') as dbf:\n",
        "  #     dbconfig = yaml.safe_load(dbf)\n",
        "\n",
        "  dbconfig = yaml.safe_load(database_yaml)\n",
        "  print(dbconfig['role'])\n",
        "\n",
        "  # assume group role to ensure shared permissions\n",
        "  @listens_for(Pool, \"connect\")\n",
        "  def assume_role(dbapi_con, connection_record):\n",
        "      logging.debug(f\"setting role {dbconfig['role']};\")\n",
        "      dbapi_con.cursor().execute(f\"set role {dbconfig['role']};\")\n",
        "      # logging.debug(f\"setting role postres;\")\n",
        "      # dbapi_con.cursor().execute(f\"set role postgres;\")\n",
        "\n",
        "  db_url = URL(\n",
        "              'postgres',\n",
        "              host=dbconfig['host'],\n",
        "              username=dbconfig['user'],\n",
        "              database=dbconfig['db'],\n",
        "              password=dbconfig['pass'],\n",
        "              port=dbconfig['port'],\n",
        "          )\n",
        "\n",
        "  db_engine = create_engine(db_url)\n",
        "\n",
        "  triage_output_path = os.path.join(user_path, 'triage_output')\n",
        "  os.makedirs(triage_output_path, exist_ok=True)\n",
        "\n",
        "  # loading config file\n",
        "  # with open('%s_triage_config.yaml' % andrew_id, 'r') as fin:\n",
        "  #     config = yaml.safe_load(fin)\n",
        "\n",
        "  config = yaml.safe_load(config_yaml)\n",
        "\n",
        "  # creating experiment object\n",
        "  experiment = MultiCoreExperiment(\n",
        "      config = config,\n",
        "      db_engine = db_engine,\n",
        "      project_path = triage_output_path,\n",
        "      n_processes=2,\n",
        "      n_db_processes=2,\n",
        "      replace=True,\n",
        "      save_predictions=True\n",
        "      )\n",
        "\n",
        "  # experiment.validate()\n",
        "  experiment.run()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyqBcKHk7lTC"
      },
      "source": [
        "## Let's run triage!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUAcMwv2qzLe",
        "outputId": "9b2d2210-790b-4dc7-9c30-cf6583ef0da6"
      },
      "source": [
        "run_triage()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "postgres\n",
            "\u001b[32m2021-12-07 22:26:22\u001b[0m - \u001b[1;30mVERBOSE\u001b[0m \u001b[34mMatrices and trained models will be saved in /content/triage_output\u001b[0m\n",
            "\u001b[32m2021-12-07 22:26:22\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mReplace flag is set to true. Matrices, models, evaluations and predictions (if exist) will be replaced\u001b[0m\n",
            "\u001b[32m2021-12-07 22:26:22\u001b[0m - \u001b[1;30m   INFO\u001b[0m No results_schema_versions table exists, which means that this installation is fresh. Upgrading db.\n",
            "\u001b[32m2021-12-07 22:26:22\u001b[0m - \u001b[1;30m   INFO\u001b[0m Context impl PostgresqlImpl.\n",
            "\u001b[32m2021-12-07 22:26:22\u001b[0m - \u001b[1;30m   INFO\u001b[0m Will assume transactional DDL.\n",
            "\u001b[32m2021-12-07 22:26:22\u001b[0m - \u001b[1;30m   INFO\u001b[0m Running upgrade  -> 8b3f167d0418, empty message\n",
            "\u001b[32m2021-12-07 22:26:22\u001b[0m - \u001b[1;30m   INFO\u001b[0m Running upgrade 8b3f167d0418 -> 0d44655e35fd, empty message\n",
            "\u001b[32m2021-12-07 22:26:22\u001b[0m - \u001b[1;30m   INFO\u001b[0m Running upgrade 0d44655e35fd -> 264245ddfce2, empty message\n",
            "\u001b[32m2021-12-07 22:26:22\u001b[0m - \u001b[1;30m   INFO\u001b[0m Running upgrade 264245ddfce2 -> 72ac5cbdca05, Change importance to float\n",
            "\u001b[32m2021-12-07 22:26:22\u001b[0m - \u001b[1;30m   INFO\u001b[0m Running upgrade 72ac5cbdca05 -> 7d57d1cf3429, empty message\n",
            "\u001b[32m2021-12-07 22:26:22\u001b[0m - \u001b[1;30m   INFO\u001b[0m Running upgrade 7d57d1cf3429 -> 89a8ce240bae, Split results into model_metadata, test_results, and train_resultss\n",
            "\u001b[32m2021-12-07 22:26:22\u001b[0m - \u001b[1;30m   INFO\u001b[0m Running upgrade 89a8ce240bae -> 2446a931de7a, Changing column names and removing redundancies in table names\n",
            "\u001b[32m2021-12-07 22:26:22\u001b[0m - \u001b[1;30m   INFO\u001b[0m Running upgrade 2446a931de7a -> d0ac573eaf1a, model_group_stored_procedure\n",
            "\u001b[32m2021-12-07 22:26:22\u001b[0m - \u001b[1;30m   INFO\u001b[0m Running upgrade d0ac573eaf1a -> 38f37d013686, Associate experiments with models and matrices\n",
            "\u001b[32m2021-12-07 22:26:22\u001b[0m - \u001b[1;30m   INFO\u001b[0m Running upgrade 38f37d013686 -> 0bca1ba9706e, add_matrix_uuid_to_eval\n",
            "\u001b[32m2021-12-07 22:26:22\u001b[0m - \u001b[1;30m   INFO\u001b[0m Running upgrade 0bca1ba9706e -> 50e1f1bc2cac, empty message\n",
            "\u001b[32m2021-12-07 22:26:22\u001b[0m - \u001b[1;30m   INFO\u001b[0m Running upgrade 50e1f1bc2cac -> cfd5c3386014, add_experiment_runs\n",
            "\u001b[32m2021-12-07 22:26:22\u001b[0m - \u001b[1;30m   INFO\u001b[0m Running upgrade cfd5c3386014 -> 97cf99b7348f, evaluation_randomness\n",
            "\u001b[32m2021-12-07 22:26:22\u001b[0m - \u001b[1;30m   INFO\u001b[0m Running upgrade 97cf99b7348f -> 609c7cc51794, rankify_predictions\n",
            "\u001b[32m2021-12-07 22:26:22\u001b[0m - \u001b[1;30m   INFO\u001b[0m Running upgrade 609c7cc51794 -> b4d7569d31cb, aequitas\n",
            "\u001b[32m2021-12-07 22:26:22\u001b[0m - \u001b[1;30m   INFO\u001b[0m Running upgrade b4d7569d31cb -> 8cef808549dd, empty message\n",
            "\u001b[32m2021-12-07 22:26:22\u001b[0m - \u001b[1;30m   INFO\u001b[0m Running upgrade 8cef808549dd -> a20104116533, empty message\n",
            "\u001b[32m2021-12-07 22:26:22\u001b[0m - \u001b[1;30m   INFO\u001b[0m Running upgrade a20104116533 -> fa1760d35710, empty message\n",
            "\u001b[32m2021-12-07 22:26:22\u001b[0m - \u001b[1;30m   INFO\u001b[0m Running upgrade fa1760d35710 -> 9bbfdcf8bab0, empty message\n",
            "\u001b[32m2021-12-07 22:26:22\u001b[0m - \u001b[1;30m   INFO\u001b[0m Running upgrade 9bbfdcf8bab0 -> 4ae804cc0977, empty message\n",
            "\u001b[32m2021-12-07 22:26:22\u001b[0m - \u001b[1;30m   INFO\u001b[0m Running upgrade 4ae804cc0977 -> a98acf92fd48, add nuke triage function\n",
            "\u001b[32m2021-12-07 22:26:22\u001b[0m - \u001b[1;30m   INFO\u001b[0m Running upgrade a98acf92fd48 -> 45219f25072b, hash-partitioning predictions tables\n",
            "\u001b[32m2021-12-07 22:26:22\u001b[0m - \u001b[1;30m   INFO\u001b[0m PostgreSQL 11 or greater found (PostgreSQL 11): Using hash partitioning\n",
            "\u001b[32m2021-12-07 22:26:23\u001b[0m - \u001b[1;30m   INFO\u001b[0m Running upgrade 45219f25072b -> 1b990cbc04e4, empty message\n",
            "\u001b[32m2021-12-07 22:26:23\u001b[0m - \u001b[1;30m   INFO\u001b[0m Running upgrade 1b990cbc04e4 -> 264786a9fe85, add label_value to prodcution table\n",
            "\u001b[32m2021-12-07 22:26:23\u001b[0m - \u001b[1;30m   INFO\u001b[0m Running upgrade 264786a9fe85 -> ce5b50ffa8e2, Break ties in list predictions\n",
            "\u001b[32m2021-12-07 22:26:23\u001b[0m - \u001b[1;30m   INFO\u001b[0m Running upgrade ce5b50ffa8e2 -> 670289044eb2, Add production prediction metadata\n",
            "\u001b[32m2021-12-07 22:26:23\u001b[0m - \u001b[1;30m   INFO\u001b[0m Running upgrade 670289044eb2 -> cdd0dc9d9870, rename production schema and list_predcitons to triage_predcition and predictions \n",
            "\u001b[32m2021-12-07 22:26:23\u001b[0m - \u001b[1;30m   INFO\u001b[0m Running upgrade 45219f25072b -> b097e47ba829, empty message\n",
            "\u001b[32m2021-12-07 22:26:23\u001b[0m - \u001b[1;30m   INFO\u001b[0m Running upgrade b097e47ba829, cdd0dc9d9870 -> 079a74c15e8b, merge b097e47ba829 with cdd0dc9d9870\n",
            "\u001b[32m2021-12-07 22:26:23\u001b[0m - \u001b[1;30m   INFO\u001b[0m Running upgrade 079a74c15e8b -> 5dd2ba8222b1, add run_type\n",
            "\u001b[32m2021-12-07 22:26:23\u001b[0m - \u001b[1;30mVERBOSE\u001b[0m \u001b[34mUsing random seed [1995] for running the experiment\u001b[0m\n",
            "\u001b[32m2021-12-07 22:26:23\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mscoring.subsets missing in the configuration file or unrecognized. No subsets will be generated\u001b[0m\n",
            "\u001b[32m2021-12-07 22:26:24\u001b[0m - \u001b[1;30mWARNING\u001b[0m \u001b[33mDEPRECATION WARNING: PercentileRankOneFeature is being replaced by BaselineRankMultiFeature. Note, however, that the scores returned by the new ranker cannot be interpreted as percentiles.\u001b[0m\n",
            "\u001b[32m2021-12-07 22:26:24\u001b[0m - \u001b[1;30mWARNING\u001b[0m \u001b[33mDEPRECATION WARNING: parameter `descend` is deprecated for PercentileRankOneFeature. Use `low_value_high_score` instead.\u001b[0m\n",
            "\u001b[32m2021-12-07 22:26:24\u001b[0m - \u001b[1;30mSUCCESS\u001b[0m \u001b[1;32mExperiment validation ran to completion with no errors\u001b[0m\n",
            "\u001b[32m2021-12-07 22:26:24\u001b[0m - \u001b[1;30mVERBOSE\u001b[0m \u001b[34mComputed and stored temporal split definitions\u001b[0m\n",
            "\u001b[32m2021-12-07 22:26:24\u001b[0m - \u001b[1;30m   INFO\u001b[0m Setting up cohort\n",
            "\u001b[32m2021-12-07 22:26:29\u001b[0m - \u001b[1;30mSUCCESS\u001b[0m \u001b[1;32mCohort setted up in the table cohort_all_entities_f3105304d8163f2c4e3cca659ddc6d9e successfully\u001b[0m\n",
            "\u001b[32m2021-12-07 22:26:29\u001b[0m - \u001b[1;30m   INFO\u001b[0m Setting up labels\n",
            "\u001b[32m2021-12-07 22:26:51\u001b[0m - \u001b[1;30mSUCCESS\u001b[0m \u001b[1;32mLabels setted up in the table labels_any_donations_5232fcedcc73b5fcb527cbfd0c0c3551 successfully \u001b[0m\n",
            "\u001b[32m2021-12-07 22:26:51\u001b[0m - \u001b[1;30m   INFO\u001b[0m Creating features tables (before imputation) \n",
            "\u001b[32m2021-12-07 22:26:51\u001b[0m - \u001b[1;30m   INFO\u001b[0m Creating collate aggregations\n",
            "\u001b[32m2021-12-07 22:26:51\u001b[0m - \u001b[1;30mVERBOSE\u001b[0m \u001b[34mStarting Feature aggregation\u001b[0m\n",
            "\u001b[32m2021-12-07 22:26:51\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mImputed feature table project_features_aggregation_imputed did not exist, need to build features\u001b[0m\n",
            "\u001b[32m2021-12-07 22:26:52\u001b[0m - \u001b[1;30m   INFO\u001b[0m Processing query tasks with 2 processes\n",
            "\u001b[32m2021-12-07 22:26:52\u001b[0m - \u001b[1;30m   INFO\u001b[0m Processing features for project_features_entity_id\n",
            "\u001b[32m2021-12-07 22:26:52\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
            "\u001b[32m2021-12-07 22:26:52\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
            "\u001b[32m2021-12-07 22:26:52\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
            "\u001b[32m2021-12-07 22:26:52\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
            "\u001b[32m2021-12-07 22:26:52\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
            "\u001b[32m2021-12-07 22:26:52\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
            "\u001b[32m2021-12-07 22:26:52\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
            "\u001b[32m2021-12-07 22:26:52\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
            "\u001b[32m2021-12-07 22:26:53\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
            "\u001b[32m2021-12-07 22:26:53\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
            "\u001b[32m2021-12-07 22:26:53\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
            "\u001b[32m2021-12-07 22:26:53\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
            "\u001b[32m2021-12-07 22:26:53\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
            "\u001b[32m2021-12-07 22:26:53\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
            "\u001b[32m2021-12-07 22:26:53\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
            "\u001b[32m2021-12-07 22:26:53\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
            "\u001b[32m2021-12-07 22:26:53\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
            "\u001b[32m2021-12-07 22:26:53\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
            "\u001b[32m2021-12-07 22:26:54\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
            "\u001b[32m2021-12-07 22:26:54\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
            "\u001b[32m2021-12-07 22:26:54\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
            "\u001b[32m2021-12-07 22:26:54\u001b[0m - \u001b[1;30m   INFO\u001b[0m Done. successes: 21, failures: 0\n",
            "\u001b[32m2021-12-07 22:26:54\u001b[0m - \u001b[1;30m   INFO\u001b[0m project_features_entity_id completed\n",
            "\u001b[32m2021-12-07 22:26:54\u001b[0m - \u001b[1;30m   INFO\u001b[0m Processing features for project_features_aggregation\n",
            "\u001b[32m2021-12-07 22:27:10\u001b[0m - \u001b[1;30m   INFO\u001b[0m Done. successes: 0, failures: 0\n",
            "\u001b[32m2021-12-07 22:27:15\u001b[0m - \u001b[1;30m   INFO\u001b[0m project_features_aggregation completed\n",
            "\u001b[32m2021-12-07 22:27:15\u001b[0m - \u001b[1;30mSUCCESS\u001b[0m \u001b[1;32mFeatures (before imputation) were stored in the tables \"features\".\"project_features_aggregation\" successfully\u001b[0m\n",
            "\u001b[32m2021-12-07 22:27:15\u001b[0m - \u001b[1;30m   INFO\u001b[0m Imputing missing values in features\n",
            "\u001b[32m2021-12-07 22:27:15\u001b[0m - \u001b[1;30mVERBOSE\u001b[0m \u001b[34mStarting Feature imputation\u001b[0m\n",
            "\u001b[32m2021-12-07 22:27:16\u001b[0m - \u001b[1;30m   INFO\u001b[0m Processing query tasks with 2 processes\n",
            "\u001b[32m2021-12-07 22:27:16\u001b[0m - \u001b[1;30m   INFO\u001b[0m Processing features for project_features_aggregation_imputed\n",
            "\u001b[32m2021-12-07 22:27:16\u001b[0m - \u001b[1;30m   INFO\u001b[0m Done. successes: 0, failures: 0\n",
            "\u001b[32m2021-12-07 22:27:16\u001b[0m - \u001b[1;30m   INFO\u001b[0m project_features_aggregation_imputed completed\n",
            "\u001b[32m2021-12-07 22:27:16\u001b[0m - \u001b[1;30mSUCCESS\u001b[0m \u001b[1;32mImputed features were stored in the tables \"features\".\"project_features_aggregation_imputed\" successfully\u001b[0m\n",
            "\u001b[32m2021-12-07 22:27:16\u001b[0m - \u001b[1;30mVERBOSE\u001b[0m \u001b[34mFound 1 total feature subsets\u001b[0m\n",
            "\u001b[32m2021-12-07 22:27:16\u001b[0m - \u001b[1;30m   INFO\u001b[0m Building matrices\n",
            "\u001b[32m2021-12-07 22:27:16\u001b[0m - \u001b[1;30mVERBOSE\u001b[0m \u001b[34mIt is necessary to build 6 matrices\u001b[0m\n",
            "\u001b[32m2021-12-07 22:27:16\u001b[0m - \u001b[1;30m   INFO\u001b[0m Starting parallel matrix building: 6 matrices, 2 processes\n",
            "\u001b[32m2021-12-07 22:27:17\u001b[0m - \u001b[1;30m   INFO\u001b[0m Matrix 2a2ba0ccc318bbe74a99726a72c323b0 saved in /content/triage_output/matrices/2a2ba0ccc318bbe74a99726a72c323b0.csv.gz\n",
            "\u001b[32m2021-12-07 22:27:18\u001b[0m - \u001b[1;30m   INFO\u001b[0m Matrix 88033d4d2e731553062324d7403af43f saved in /content/triage_output/matrices/88033d4d2e731553062324d7403af43f.csv.gz\n",
            "\u001b[32m2021-12-07 22:27:19\u001b[0m - \u001b[1;30m   INFO\u001b[0m Matrix 10f30faf4d136757ef3f11d9b3e5bdc2 saved in /content/triage_output/matrices/10f30faf4d136757ef3f11d9b3e5bdc2.csv.gz\n",
            "\u001b[32m2021-12-07 22:27:19\u001b[0m - \u001b[1;30m   INFO\u001b[0m Matrix cc681ad650fafd044897af6bd73ab167 saved in /content/triage_output/matrices/cc681ad650fafd044897af6bd73ab167.csv.gz\n",
            "\u001b[32m2021-12-07 22:27:20\u001b[0m - \u001b[1;30m   INFO\u001b[0m Matrix 76c9a74b579fcdc3747e18fdfa286e35 saved in /content/triage_output/matrices/76c9a74b579fcdc3747e18fdfa286e35.csv.gz\n",
            "\u001b[32m2021-12-07 22:27:20\u001b[0m - \u001b[1;30m   INFO\u001b[0m Matrix f8772c9ca6484d2f32a7e8258f6dbc64 saved in /content/triage_output/matrices/f8772c9ca6484d2f32a7e8258f6dbc64.csv.gz\n",
            "\u001b[32m2021-12-07 22:27:20\u001b[0m - \u001b[1;30m   INFO\u001b[0m Done. successes: 6, failures: 0\n",
            "\u001b[32m2021-12-07 22:27:20\u001b[0m - \u001b[1;30mSUCCESS\u001b[0m \u001b[1;32mMatrices were stored in /content/triage_output/matrices successfully\u001b[0m\n",
            "\u001b[32m2021-12-07 22:27:20\u001b[0m - \u001b[1;30m   INFO\u001b[0m Starting parallel subset creation: 0 subsets, 2 processes\n",
            "\u001b[32m2021-12-07 22:27:20\u001b[0m - \u001b[1;30m   INFO\u001b[0m Done. successes: 0, failures: 0\n",
            "\u001b[32m2021-12-07 22:27:22\u001b[0m - \u001b[1;30mSUCCESS\u001b[0m \u001b[1;32mProtected groups stored in the table protected_groups_cf250342c293e834c6fa34f241461aef successfully\u001b[0m\n",
            "\u001b[32m2021-12-07 22:27:22\u001b[0m - \u001b[1;30mVERBOSE\u001b[0m \u001b[34mSplit train/test tasks into three task batches. - each batch has models from all splits\u001b[0m\n",
            "\u001b[32m2021-12-07 22:27:22\u001b[0m - \u001b[1;30mVERBOSE\u001b[0m \u001b[34mBatch 1: Baselines or simple classifiers (e.g. DecisionTree, SLR) (9 tasks total)\u001b[0m\n",
            "\u001b[32m2021-12-07 22:27:22\u001b[0m - \u001b[1;30mVERBOSE\u001b[0m \u001b[34mBatch 2: Heavyweight classifiers. (3 tasks total)\u001b[0m\n",
            "\u001b[32m2021-12-07 22:27:22\u001b[0m - \u001b[1;30mVERBOSE\u001b[0m \u001b[34mBatch 3: All classifiers not found in one of the other batches. (0 tasks total)\u001b[0m\n",
            "\u001b[32m2021-12-07 22:27:22\u001b[0m - \u001b[1;30m   INFO\u001b[0m 4 models groups will be trained, tested and evaluated\n",
            "\u001b[32m2021-12-07 22:27:22\u001b[0m - \u001b[1;30m   INFO\u001b[0m Training, testing and evaluating models\n",
            "\u001b[32m2021-12-07 22:27:22\u001b[0m - \u001b[1;30mVERBOSE\u001b[0m \u001b[34m3 train/test tasks found.\u001b[0m\n",
            "\u001b[32m2021-12-07 22:27:22\u001b[0m - \u001b[1;30m   INFO\u001b[0m Starting parallelizable batch train/testing with 9 tasks, 2 processes\n",
            "\u001b[32m2021-12-07 22:27:22\u001b[0m - \u001b[1;30mVERBOSE\u001b[0m \u001b[34mTraining sklearn.tree.DecisionTreeClassifier({'max_depth': 3, 'max_features': None, 'min_samples_split': 25}) [395896e2f4506e13d4ebe536c72f4d81] on train matrix 88033d4d2e731553062324d7403af43f\u001b[0m\n",
            "\u001b[32m2021-12-07 22:27:22\u001b[0m - \u001b[1;30mVERBOSE\u001b[0m \u001b[34mTraining triage.component.catwalk.estimators.classifiers.ScaledLogisticRegression({'C': 0.1, 'penalty': 'l1'}) [58b2330d957c967f3e9de50a09eca3da] on train matrix 88033d4d2e731553062324d7403af43f\u001b[0m\n",
            "\u001b[32m2021-12-07 22:27:22\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mYou got feature values that are out of the range: (0, 1). The feature values will cutoff to fit in the range (0, 1).\u001b[0m\n",
            "\u001b[32m2021-12-07 22:27:22\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mModel 1, not found from previous runs. Adding the new model\u001b[0m\n",
            "\u001b[32m2021-12-07 22:27:22\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mModel 2, not found from previous runs. Adding the new model\u001b[0m\n",
            "\u001b[32m2021-12-07 22:27:22\u001b[0m - \u001b[1;30mWARNING\u001b[0m \u001b[33mThe selected algorithm, doesn't support a standard way of calculate the importance of each feature used. Falling back to ad-hoc methods (e.g. in LogisticRegression we will return Odd Ratios instead coefficients)\u001b[0m\n",
            "\u001b[32m2021-12-07 22:27:22\u001b[0m - \u001b[1;30mSUCCESS\u001b[0m \u001b[1;32mTrained model id 1: sklearn.tree.DecisionTreeClassifier({'max_depth': 3, 'max_features': None, 'min_samples_split': 25}) [395896e2f4506e13d4ebe536c72f4d81] on train matrix 88033d4d2e731553062324d7403af43f. \u001b[0m\n",
            "\u001b[32m2021-12-07 22:27:22\u001b[0m - \u001b[1;30mSUCCESS\u001b[0m \u001b[1;32mTrained model id 2: triage.component.catwalk.estimators.classifiers.ScaledLogisticRegression({'C': 0.1, 'penalty': 'l1'}) [58b2330d957c967f3e9de50a09eca3da] on train matrix 88033d4d2e731553062324d7403af43f. \u001b[0m\n",
            "\u001b[32m2021-12-07 22:27:22\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mYou got feature values that are out of the range: (0, 1). The feature values will cutoff to fit in the range (0, 1).\u001b[0m\n",
            "\u001b[32m2021-12-07 22:27:33\u001b[0m - \u001b[1;30m   INFO\u001b[0m NumExpr defaulting to 2 threads.\n",
            "\u001b[32m2021-12-07 22:27:33\u001b[0m - \u001b[1;30m   INFO\u001b[0m getcrosstabs: attribute columns to perform crosstabs:teacher_prefix\n",
            "\u001b[32m2021-12-07 22:27:33\u001b[0m - \u001b[1;30m   INFO\u001b[0m NumExpr defaulting to 2 threads.\n",
            "\u001b[32m2021-12-07 22:27:33\u001b[0m - \u001b[1;30m   INFO\u001b[0m getcrosstabs: attribute columns to perform crosstabs:teacher_prefix\n",
            "get_disparity_predefined_group()\n",
            "\u001b[32m2021-12-07 22:27:34\u001b[0m - \u001b[1;30m   INFO\u001b[0m get_group_value_fairness...\n",
            "\u001b[32m2021-12-07 22:27:35\u001b[0m - \u001b[1;30m   INFO\u001b[0m getcrosstabs: attribute columns to perform crosstabs:teacher_prefix\n",
            "get_disparity_predefined_group()\n",
            "\u001b[32m2021-12-07 22:27:35\u001b[0m - \u001b[1;30m   INFO\u001b[0m get_group_value_fairness...\n",
            "\u001b[32m2021-12-07 22:27:35\u001b[0m - \u001b[1;30m   INFO\u001b[0m getcrosstabs: attribute columns to perform crosstabs:teacher_prefix\n",
            "get_disparity_predefined_group()\n",
            "\u001b[32m2021-12-07 22:27:36\u001b[0m - \u001b[1;30m   INFO\u001b[0m get_group_value_fairness...\n",
            "\u001b[32m2021-12-07 22:27:36\u001b[0m - \u001b[1;30m   INFO\u001b[0m Model 2 evaluation on test matrix 2a2ba0ccc318bbe74a99726a72c323b0 completed.\n",
            "get_disparity_predefined_group()\n",
            "\u001b[32m2021-12-07 22:27:36\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mYou got feature values that are out of the range: (0, 1). The feature values will cutoff to fit in the range (0, 1).\u001b[0m\n",
            "\u001b[32m2021-12-07 22:27:36\u001b[0m - \u001b[1;30m   INFO\u001b[0m get_group_value_fairness...\n",
            "\u001b[32m2021-12-07 22:27:36\u001b[0m - \u001b[1;30m   INFO\u001b[0m Model 1 evaluation on test matrix 2a2ba0ccc318bbe74a99726a72c323b0 completed.\n",
            "\u001b[32m2021-12-07 22:27:49\u001b[0m - \u001b[1;30m   INFO\u001b[0m getcrosstabs: attribute columns to perform crosstabs:teacher_prefix\n",
            "\u001b[32m2021-12-07 22:27:49\u001b[0m - \u001b[1;30m   INFO\u001b[0m getcrosstabs: attribute columns to perform crosstabs:teacher_prefix\n",
            "get_disparity_predefined_group()\n",
            "\u001b[32m2021-12-07 22:27:50\u001b[0m - \u001b[1;30m   INFO\u001b[0m get_group_value_fairness...\n",
            "\u001b[32m2021-12-07 22:27:50\u001b[0m - \u001b[1;30m   INFO\u001b[0m getcrosstabs: attribute columns to perform crosstabs:teacher_prefix\n",
            "get_disparity_predefined_group()\n",
            "\u001b[32m2021-12-07 22:27:50\u001b[0m - \u001b[1;30m   INFO\u001b[0m get_group_value_fairness...\n",
            "\u001b[32m2021-12-07 22:27:51\u001b[0m - \u001b[1;30m   INFO\u001b[0m getcrosstabs: attribute columns to perform crosstabs:teacher_prefix\n",
            "get_disparity_predefined_group()\n",
            "\u001b[32m2021-12-07 22:27:51\u001b[0m - \u001b[1;30m   INFO\u001b[0m get_group_value_fairness...\n",
            "\u001b[32m2021-12-07 22:27:51\u001b[0m - \u001b[1;30m   INFO\u001b[0m Model 2 evaluation on train matrix 88033d4d2e731553062324d7403af43f completed.\n",
            "\u001b[32m2021-12-07 22:27:52\u001b[0m - \u001b[1;30mVERBOSE\u001b[0m \u001b[34mTraining triage.component.catwalk.baselines.rankers.PercentileRankOneFeature({'descend': False, 'feature': 'project_features_entity_id_all_total_asking_price_sum'}) [fae0c1a55e7c9bd9fa9064b2cd481371] on train matrix 88033d4d2e731553062324d7403af43f\u001b[0m\n",
            "\u001b[32m2021-12-07 22:27:52\u001b[0m - \u001b[1;30mWARNING\u001b[0m \u001b[33mDEPRECATION WARNING: PercentileRankOneFeature is being replaced by BaselineRankMultiFeature. Note, however, that the scores returned by the new ranker cannot be interpreted as percentiles.\u001b[0m\n",
            "\u001b[32m2021-12-07 22:27:52\u001b[0m - \u001b[1;30mWARNING\u001b[0m \u001b[33mDEPRECATION WARNING: parameter `descend` is deprecated for PercentileRankOneFeature. Use `low_value_high_score` instead.\u001b[0m\n",
            "\u001b[32m2021-12-07 22:27:52\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mModel 3, not found from previous runs. Adding the new model\u001b[0m\n",
            "\u001b[32m2021-12-07 22:27:52\u001b[0m - \u001b[1;30mSUCCESS\u001b[0m \u001b[1;32mTrained model id 3: triage.component.catwalk.baselines.rankers.PercentileRankOneFeature({'descend': False, 'feature': 'project_features_entity_id_all_total_asking_price_sum'}) [fae0c1a55e7c9bd9fa9064b2cd481371] on train matrix 88033d4d2e731553062324d7403af43f. \u001b[0m\n",
            "get_disparity_predefined_group()\n",
            "\u001b[32m2021-12-07 22:27:52\u001b[0m - \u001b[1;30m   INFO\u001b[0m get_group_value_fairness...\n",
            "\u001b[32m2021-12-07 22:27:52\u001b[0m - \u001b[1;30m   INFO\u001b[0m Model 1 evaluation on train matrix 88033d4d2e731553062324d7403af43f completed.\n",
            "\u001b[32m2021-12-07 22:27:52\u001b[0m - \u001b[1;30mVERBOSE\u001b[0m \u001b[34mTraining sklearn.tree.DecisionTreeClassifier({'max_depth': 3, 'max_features': None, 'min_samples_split': 25}) [232a3978ccf34b167884daf702e8ed26] on train matrix 10f30faf4d136757ef3f11d9b3e5bdc2\u001b[0m\n",
            "\u001b[32m2021-12-07 22:27:52\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mModel 4, not found from previous runs. Adding the new model\u001b[0m\n",
            "\u001b[32m2021-12-07 22:27:52\u001b[0m - \u001b[1;30mSUCCESS\u001b[0m \u001b[1;32mTrained model id 4: sklearn.tree.DecisionTreeClassifier({'max_depth': 3, 'max_features': None, 'min_samples_split': 25}) [232a3978ccf34b167884daf702e8ed26] on train matrix 10f30faf4d136757ef3f11d9b3e5bdc2. \u001b[0m\n",
            "\u001b[32m2021-12-07 22:27:53\u001b[0m - \u001b[1;30m   INFO\u001b[0m NumExpr defaulting to 2 threads.\n",
            "\u001b[32m2021-12-07 22:27:53\u001b[0m - \u001b[1;30m   INFO\u001b[0m getcrosstabs: attribute columns to perform crosstabs:teacher_prefix\n",
            "get_disparity_predefined_group()\n",
            "\u001b[32m2021-12-07 22:27:55\u001b[0m - \u001b[1;30m   INFO\u001b[0m get_group_value_fairness...\n",
            "\u001b[32m2021-12-07 22:27:55\u001b[0m - \u001b[1;30m   INFO\u001b[0m getcrosstabs: attribute columns to perform crosstabs:teacher_prefix\n",
            "get_disparity_predefined_group()\n",
            "\u001b[32m2021-12-07 22:27:56\u001b[0m - \u001b[1;30m   INFO\u001b[0m get_group_value_fairness...\n",
            "\u001b[32m2021-12-07 22:27:56\u001b[0m - \u001b[1;30m   INFO\u001b[0m Model 3 evaluation on test matrix 2a2ba0ccc318bbe74a99726a72c323b0 completed.\n",
            "\u001b[32m2021-12-07 22:27:58\u001b[0m - \u001b[1;30m   INFO\u001b[0m getcrosstabs: attribute columns to perform crosstabs:teacher_prefix\n",
            "get_disparity_predefined_group()\n",
            "\u001b[32m2021-12-07 22:27:59\u001b[0m - \u001b[1;30m   INFO\u001b[0m get_group_value_fairness...\n",
            "\u001b[32m2021-12-07 22:27:59\u001b[0m - \u001b[1;30m   INFO\u001b[0m getcrosstabs: attribute columns to perform crosstabs:teacher_prefix\n",
            "get_disparity_predefined_group()\n",
            "\u001b[32m2021-12-07 22:28:01\u001b[0m - \u001b[1;30m   INFO\u001b[0m get_group_value_fairness...\n",
            "\u001b[32m2021-12-07 22:28:01\u001b[0m - \u001b[1;30m   INFO\u001b[0m Model 3 evaluation on train matrix 88033d4d2e731553062324d7403af43f completed.\n",
            "\u001b[32m2021-12-07 22:28:01\u001b[0m - \u001b[1;30mVERBOSE\u001b[0m \u001b[34mTraining triage.component.catwalk.estimators.classifiers.ScaledLogisticRegression({'C': 0.1, 'penalty': 'l1'}) [b21e79f1c30cf98f035f493fd8dae06c] on train matrix 10f30faf4d136757ef3f11d9b3e5bdc2\u001b[0m\n",
            "\u001b[32m2021-12-07 22:28:01\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mModel 5, not found from previous runs. Adding the new model\u001b[0m\n",
            "\u001b[32m2021-12-07 22:28:01\u001b[0m - \u001b[1;30mWARNING\u001b[0m \u001b[33mThe selected algorithm, doesn't support a standard way of calculate the importance of each feature used. Falling back to ad-hoc methods (e.g. in LogisticRegression we will return Odd Ratios instead coefficients)\u001b[0m\n",
            "\u001b[32m2021-12-07 22:28:01\u001b[0m - \u001b[1;30mSUCCESS\u001b[0m \u001b[1;32mTrained model id 5: triage.component.catwalk.estimators.classifiers.ScaledLogisticRegression({'C': 0.1, 'penalty': 'l1'}) [b21e79f1c30cf98f035f493fd8dae06c] on train matrix 10f30faf4d136757ef3f11d9b3e5bdc2. \u001b[0m\n",
            "\u001b[32m2021-12-07 22:28:01\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mYou got feature values that are out of the range: (0, 1). The feature values will cutoff to fit in the range (0, 1).\u001b[0m\n",
            "\u001b[32m2021-12-07 22:28:05\u001b[0m - \u001b[1;30m   INFO\u001b[0m NumExpr defaulting to 2 threads.\n",
            "\u001b[32m2021-12-07 22:28:05\u001b[0m - \u001b[1;30m   INFO\u001b[0m getcrosstabs: attribute columns to perform crosstabs:teacher_prefix\n",
            "get_disparity_predefined_group()\n",
            "\u001b[32m2021-12-07 22:28:07\u001b[0m - \u001b[1;30m   INFO\u001b[0m get_group_value_fairness...\n",
            "\u001b[32m2021-12-07 22:28:07\u001b[0m - \u001b[1;30m   INFO\u001b[0m getcrosstabs: attribute columns to perform crosstabs:teacher_prefix\n",
            "get_disparity_predefined_group()\n",
            "\u001b[32m2021-12-07 22:28:08\u001b[0m - \u001b[1;30m   INFO\u001b[0m get_group_value_fairness...\n",
            "\u001b[32m2021-12-07 22:28:08\u001b[0m - \u001b[1;30m   INFO\u001b[0m Model 4 evaluation on test matrix cc681ad650fafd044897af6bd73ab167 completed.\n",
            "\u001b[32m2021-12-07 22:28:15\u001b[0m - \u001b[1;30m   INFO\u001b[0m NumExpr defaulting to 2 threads.\n",
            "\u001b[32m2021-12-07 22:28:15\u001b[0m - \u001b[1;30m   INFO\u001b[0m getcrosstabs: attribute columns to perform crosstabs:teacher_prefix\n",
            "get_disparity_predefined_group()\n",
            "\u001b[32m2021-12-07 22:28:16\u001b[0m - \u001b[1;30m   INFO\u001b[0m get_group_value_fairness...\n",
            "\u001b[32m2021-12-07 22:28:16\u001b[0m - \u001b[1;30m   INFO\u001b[0m getcrosstabs: attribute columns to perform crosstabs:teacher_prefix\n",
            "get_disparity_predefined_group()\n",
            "\u001b[32m2021-12-07 22:28:17\u001b[0m - \u001b[1;30m   INFO\u001b[0m get_group_value_fairness...\n",
            "\u001b[32m2021-12-07 22:28:18\u001b[0m - \u001b[1;30m   INFO\u001b[0m Model 5 evaluation on test matrix cc681ad650fafd044897af6bd73ab167 completed.\n",
            "\u001b[32m2021-12-07 22:28:25\u001b[0m - \u001b[1;30m   INFO\u001b[0m getcrosstabs: attribute columns to perform crosstabs:teacher_prefix\n",
            "get_disparity_predefined_group()\n",
            "\u001b[32m2021-12-07 22:28:26\u001b[0m - \u001b[1;30m   INFO\u001b[0m get_group_value_fairness...\n",
            "\u001b[32m2021-12-07 22:28:26\u001b[0m - \u001b[1;30m   INFO\u001b[0m getcrosstabs: attribute columns to perform crosstabs:teacher_prefix\n",
            "get_disparity_predefined_group()\n",
            "\u001b[32m2021-12-07 22:28:28\u001b[0m - \u001b[1;30m   INFO\u001b[0m get_group_value_fairness...\n",
            "\u001b[32m2021-12-07 22:28:28\u001b[0m - \u001b[1;30m   INFO\u001b[0m Model 4 evaluation on train matrix 10f30faf4d136757ef3f11d9b3e5bdc2 completed.\n",
            "\u001b[32m2021-12-07 22:28:28\u001b[0m - \u001b[1;30mVERBOSE\u001b[0m \u001b[34mTraining triage.component.catwalk.baselines.rankers.PercentileRankOneFeature({'descend': False, 'feature': 'project_features_entity_id_all_total_asking_price_sum'}) [dd806432f4bfd195aade5a559cf076d2] on train matrix 10f30faf4d136757ef3f11d9b3e5bdc2\u001b[0m\n",
            "\u001b[32m2021-12-07 22:28:28\u001b[0m - \u001b[1;30mWARNING\u001b[0m \u001b[33mDEPRECATION WARNING: PercentileRankOneFeature is being replaced by BaselineRankMultiFeature. Note, however, that the scores returned by the new ranker cannot be interpreted as percentiles.\u001b[0m\n",
            "\u001b[32m2021-12-07 22:28:28\u001b[0m - \u001b[1;30mWARNING\u001b[0m \u001b[33mDEPRECATION WARNING: parameter `descend` is deprecated for PercentileRankOneFeature. Use `low_value_high_score` instead.\u001b[0m\n",
            "\u001b[32m2021-12-07 22:28:28\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mModel 6, not found from previous runs. Adding the new model\u001b[0m\n",
            "\u001b[32m2021-12-07 22:28:28\u001b[0m - \u001b[1;30mSUCCESS\u001b[0m \u001b[1;32mTrained model id 6: triage.component.catwalk.baselines.rankers.PercentileRankOneFeature({'descend': False, 'feature': 'project_features_entity_id_all_total_asking_price_sum'}) [dd806432f4bfd195aade5a559cf076d2] on train matrix 10f30faf4d136757ef3f11d9b3e5bdc2. \u001b[0m\n",
            "\u001b[32m2021-12-07 22:28:30\u001b[0m - \u001b[1;30m   INFO\u001b[0m NumExpr defaulting to 2 threads.\n",
            "\u001b[32m2021-12-07 22:28:30\u001b[0m - \u001b[1;30m   INFO\u001b[0m getcrosstabs: attribute columns to perform crosstabs:teacher_prefix\n",
            "get_disparity_predefined_group()\n",
            "\u001b[32m2021-12-07 22:28:31\u001b[0m - \u001b[1;30m   INFO\u001b[0m get_group_value_fairness...\n",
            "\u001b[32m2021-12-07 22:28:31\u001b[0m - \u001b[1;30m   INFO\u001b[0m getcrosstabs: attribute columns to perform crosstabs:teacher_prefix\n",
            "get_disparity_predefined_group()\n",
            "\u001b[32m2021-12-07 22:28:32\u001b[0m - \u001b[1;30m   INFO\u001b[0m get_group_value_fairness...\n",
            "\u001b[32m2021-12-07 22:28:33\u001b[0m - \u001b[1;30m   INFO\u001b[0m Model 6 evaluation on test matrix cc681ad650fafd044897af6bd73ab167 completed.\n",
            "\u001b[32m2021-12-07 22:28:34\u001b[0m - \u001b[1;30m   INFO\u001b[0m getcrosstabs: attribute columns to perform crosstabs:teacher_prefix\n",
            "\u001b[32m2021-12-07 22:28:35\u001b[0m - \u001b[1;30m   INFO\u001b[0m getcrosstabs: attribute columns to perform crosstabs:teacher_prefix\n",
            "get_disparity_predefined_group()\n",
            "\u001b[32m2021-12-07 22:28:35\u001b[0m - \u001b[1;30m   INFO\u001b[0m get_group_value_fairness...\n",
            "\u001b[32m2021-12-07 22:28:35\u001b[0m - \u001b[1;30m   INFO\u001b[0m getcrosstabs: attribute columns to perform crosstabs:teacher_prefix\n",
            "get_disparity_predefined_group()\n",
            "\u001b[32m2021-12-07 22:28:36\u001b[0m - \u001b[1;30m   INFO\u001b[0m get_group_value_fairness...\n",
            "\u001b[32m2021-12-07 22:28:37\u001b[0m - \u001b[1;30m   INFO\u001b[0m getcrosstabs: attribute columns to perform crosstabs:teacher_prefix\n",
            "get_disparity_predefined_group()\n",
            "\u001b[32m2021-12-07 22:28:37\u001b[0m - \u001b[1;30m   INFO\u001b[0m get_group_value_fairness...\n",
            "\u001b[32m2021-12-07 22:28:37\u001b[0m - \u001b[1;30m   INFO\u001b[0m Model 5 evaluation on train matrix 10f30faf4d136757ef3f11d9b3e5bdc2 completed.\n",
            "\u001b[32m2021-12-07 22:28:37\u001b[0m - \u001b[1;30mVERBOSE\u001b[0m \u001b[34mTraining sklearn.tree.DecisionTreeClassifier({'max_depth': 3, 'max_features': None, 'min_samples_split': 25}) [4b37802241efcfae1e82485fb3f48ef9] on train matrix f8772c9ca6484d2f32a7e8258f6dbc64\u001b[0m\n",
            "\u001b[32m2021-12-07 22:28:37\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mModel 7, not found from previous runs. Adding the new model\u001b[0m\n",
            "\u001b[32m2021-12-07 22:28:37\u001b[0m - \u001b[1;30mSUCCESS\u001b[0m \u001b[1;32mTrained model id 7: sklearn.tree.DecisionTreeClassifier({'max_depth': 3, 'max_features': None, 'min_samples_split': 25}) [4b37802241efcfae1e82485fb3f48ef9] on train matrix f8772c9ca6484d2f32a7e8258f6dbc64. \u001b[0m\n",
            "get_disparity_predefined_group()\n",
            "\u001b[32m2021-12-07 22:28:38\u001b[0m - \u001b[1;30m   INFO\u001b[0m get_group_value_fairness...\n",
            "\u001b[32m2021-12-07 22:28:38\u001b[0m - \u001b[1;30m   INFO\u001b[0m Model 6 evaluation on train matrix 10f30faf4d136757ef3f11d9b3e5bdc2 completed.\n",
            "\u001b[32m2021-12-07 22:28:38\u001b[0m - \u001b[1;30mVERBOSE\u001b[0m \u001b[34mTraining triage.component.catwalk.estimators.classifiers.ScaledLogisticRegression({'C': 0.1, 'penalty': 'l1'}) [21c8665d4b12f8f095c90dd0bf0d5f68] on train matrix f8772c9ca6484d2f32a7e8258f6dbc64\u001b[0m\n",
            "\u001b[32m2021-12-07 22:28:38\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mModel 8, not found from previous runs. Adding the new model\u001b[0m\n",
            "\u001b[32m2021-12-07 22:28:38\u001b[0m - \u001b[1;30mWARNING\u001b[0m \u001b[33mThe selected algorithm, doesn't support a standard way of calculate the importance of each feature used. Falling back to ad-hoc methods (e.g. in LogisticRegression we will return Odd Ratios instead coefficients)\u001b[0m\n",
            "\u001b[32m2021-12-07 22:28:38\u001b[0m - \u001b[1;30mSUCCESS\u001b[0m \u001b[1;32mTrained model id 8: triage.component.catwalk.estimators.classifiers.ScaledLogisticRegression({'C': 0.1, 'penalty': 'l1'}) [21c8665d4b12f8f095c90dd0bf0d5f68] on train matrix f8772c9ca6484d2f32a7e8258f6dbc64. \u001b[0m\n",
            "\u001b[32m2021-12-07 22:28:49\u001b[0m - \u001b[1;30m   INFO\u001b[0m NumExpr defaulting to 2 threads.\n",
            "\u001b[32m2021-12-07 22:28:50\u001b[0m - \u001b[1;30m   INFO\u001b[0m getcrosstabs: attribute columns to perform crosstabs:teacher_prefix\n",
            "\u001b[32m2021-12-07 22:28:50\u001b[0m - \u001b[1;30m   INFO\u001b[0m NumExpr defaulting to 2 threads.\n",
            "\u001b[32m2021-12-07 22:28:50\u001b[0m - \u001b[1;30m   INFO\u001b[0m getcrosstabs: attribute columns to perform crosstabs:teacher_prefix\n",
            "get_disparity_predefined_group()\n",
            "\u001b[32m2021-12-07 22:28:51\u001b[0m - \u001b[1;30m   INFO\u001b[0m get_group_value_fairness...\n",
            "\u001b[32m2021-12-07 22:28:51\u001b[0m - \u001b[1;30m   INFO\u001b[0m getcrosstabs: attribute columns to perform crosstabs:teacher_prefix\n",
            "get_disparity_predefined_group()\n",
            "\u001b[32m2021-12-07 22:28:52\u001b[0m - \u001b[1;30m   INFO\u001b[0m get_group_value_fairness...\n",
            "\u001b[32m2021-12-07 22:28:52\u001b[0m - \u001b[1;30m   INFO\u001b[0m getcrosstabs: attribute columns to perform crosstabs:teacher_prefix\n",
            "get_disparity_predefined_group()\n",
            "\u001b[32m2021-12-07 22:28:52\u001b[0m - \u001b[1;30m   INFO\u001b[0m get_group_value_fairness...\n",
            "\u001b[32m2021-12-07 22:28:52\u001b[0m - \u001b[1;30m   INFO\u001b[0m Model 7 evaluation on test matrix 76c9a74b579fcdc3747e18fdfa286e35 completed.\n",
            "get_disparity_predefined_group()\n",
            "\u001b[32m2021-12-07 22:28:53\u001b[0m - \u001b[1;30m   INFO\u001b[0m get_group_value_fairness...\n",
            "\u001b[32m2021-12-07 22:28:53\u001b[0m - \u001b[1;30m   INFO\u001b[0m Model 8 evaluation on test matrix 76c9a74b579fcdc3747e18fdfa286e35 completed.\n",
            "\u001b[32m2021-12-07 22:29:12\u001b[0m - \u001b[1;30m   INFO\u001b[0m getcrosstabs: attribute columns to perform crosstabs:teacher_prefix\n",
            "\u001b[32m2021-12-07 22:29:13\u001b[0m - \u001b[1;30m   INFO\u001b[0m getcrosstabs: attribute columns to perform crosstabs:teacher_prefix\n",
            "get_disparity_predefined_group()\n",
            "\u001b[32m2021-12-07 22:29:13\u001b[0m - \u001b[1;30m   INFO\u001b[0m get_group_value_fairness...\n",
            "\u001b[32m2021-12-07 22:29:13\u001b[0m - \u001b[1;30m   INFO\u001b[0m getcrosstabs: attribute columns to perform crosstabs:teacher_prefix\n",
            "get_disparity_predefined_group()\n",
            "\u001b[32m2021-12-07 22:29:14\u001b[0m - \u001b[1;30m   INFO\u001b[0m get_group_value_fairness...\n",
            "\u001b[32m2021-12-07 22:29:14\u001b[0m - \u001b[1;30m   INFO\u001b[0m getcrosstabs: attribute columns to perform crosstabs:teacher_prefix\n",
            "get_disparity_predefined_group()\n",
            "\u001b[32m2021-12-07 22:29:14\u001b[0m - \u001b[1;30m   INFO\u001b[0m get_group_value_fairness...\n",
            "\u001b[32m2021-12-07 22:29:15\u001b[0m - \u001b[1;30m   INFO\u001b[0m Model 7 evaluation on train matrix f8772c9ca6484d2f32a7e8258f6dbc64 completed.\n",
            "\u001b[32m2021-12-07 22:29:15\u001b[0m - \u001b[1;30mVERBOSE\u001b[0m \u001b[34mTraining triage.component.catwalk.baselines.rankers.PercentileRankOneFeature({'descend': False, 'feature': 'project_features_entity_id_all_total_asking_price_sum'}) [3510f611b7ec6e3c4751ba0f81170d63] on train matrix f8772c9ca6484d2f32a7e8258f6dbc64\u001b[0m\n",
            "\u001b[32m2021-12-07 22:29:15\u001b[0m - \u001b[1;30mWARNING\u001b[0m \u001b[33mDEPRECATION WARNING: PercentileRankOneFeature is being replaced by BaselineRankMultiFeature. Note, however, that the scores returned by the new ranker cannot be interpreted as percentiles.\u001b[0m\n",
            "\u001b[32m2021-12-07 22:29:15\u001b[0m - \u001b[1;30mWARNING\u001b[0m \u001b[33mDEPRECATION WARNING: parameter `descend` is deprecated for PercentileRankOneFeature. Use `low_value_high_score` instead.\u001b[0m\n",
            "\u001b[32m2021-12-07 22:29:15\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mModel 9, not found from previous runs. Adding the new model\u001b[0m\n",
            "\u001b[32m2021-12-07 22:29:15\u001b[0m - \u001b[1;30mSUCCESS\u001b[0m \u001b[1;32mTrained model id 9: triage.component.catwalk.baselines.rankers.PercentileRankOneFeature({'descend': False, 'feature': 'project_features_entity_id_all_total_asking_price_sum'}) [3510f611b7ec6e3c4751ba0f81170d63] on train matrix f8772c9ca6484d2f32a7e8258f6dbc64. \u001b[0m\n",
            "get_disparity_predefined_group()\n",
            "\u001b[32m2021-12-07 22:29:15\u001b[0m - \u001b[1;30m   INFO\u001b[0m get_group_value_fairness...\n",
            "\u001b[32m2021-12-07 22:29:15\u001b[0m - \u001b[1;30m   INFO\u001b[0m Model 8 evaluation on train matrix f8772c9ca6484d2f32a7e8258f6dbc64 completed.\n",
            "\u001b[32m2021-12-07 22:29:16\u001b[0m - \u001b[1;30m   INFO\u001b[0m NumExpr defaulting to 2 threads.\n",
            "\u001b[32m2021-12-07 22:29:16\u001b[0m - \u001b[1;30m   INFO\u001b[0m getcrosstabs: attribute columns to perform crosstabs:teacher_prefix\n",
            "get_disparity_predefined_group()\n",
            "\u001b[32m2021-12-07 22:29:17\u001b[0m - \u001b[1;30m   INFO\u001b[0m get_group_value_fairness...\n",
            "\u001b[32m2021-12-07 22:29:17\u001b[0m - \u001b[1;30m   INFO\u001b[0m getcrosstabs: attribute columns to perform crosstabs:teacher_prefix\n",
            "get_disparity_predefined_group()\n",
            "\u001b[32m2021-12-07 22:29:18\u001b[0m - \u001b[1;30m   INFO\u001b[0m get_group_value_fairness...\n",
            "\u001b[32m2021-12-07 22:29:18\u001b[0m - \u001b[1;30m   INFO\u001b[0m Model 9 evaluation on test matrix 76c9a74b579fcdc3747e18fdfa286e35 completed.\n",
            "\u001b[32m2021-12-07 22:29:20\u001b[0m - \u001b[1;30m   INFO\u001b[0m getcrosstabs: attribute columns to perform crosstabs:teacher_prefix\n",
            "get_disparity_predefined_group()\n",
            "\u001b[32m2021-12-07 22:29:21\u001b[0m - \u001b[1;30m   INFO\u001b[0m get_group_value_fairness...\n",
            "\u001b[32m2021-12-07 22:29:21\u001b[0m - \u001b[1;30m   INFO\u001b[0m getcrosstabs: attribute columns to perform crosstabs:teacher_prefix\n",
            "get_disparity_predefined_group()\n",
            "\u001b[32m2021-12-07 22:29:21\u001b[0m - \u001b[1;30m   INFO\u001b[0m get_group_value_fairness...\n",
            "\u001b[32m2021-12-07 22:29:22\u001b[0m - \u001b[1;30m   INFO\u001b[0m Model 9 evaluation on train matrix f8772c9ca6484d2f32a7e8258f6dbc64 completed.\n",
            "\u001b[32m2021-12-07 22:29:22\u001b[0m - \u001b[1;30m   INFO\u001b[0m Done. successes: 9, failures: 0\n",
            "\u001b[32m2021-12-07 22:29:22\u001b[0m - \u001b[1;30m   INFO\u001b[0m Starting parallelizable batch train/testing with 3 tasks, 1 processes\n",
            "\u001b[32m2021-12-07 22:29:22\u001b[0m - \u001b[1;30mVERBOSE\u001b[0m \u001b[34mTraining sklearn.ensemble.RandomForestClassifier({'max_depth': 50, 'min_samples_split': 25, 'n_estimators': 150}) [afe9d61f915aed6702fc598ceb66fdaf] on train matrix 88033d4d2e731553062324d7403af43f\u001b[0m\n",
            "\u001b[32m2021-12-07 22:29:22\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mModel 10, not found from previous runs. Adding the new model\u001b[0m\n",
            "\u001b[32m2021-12-07 22:29:22\u001b[0m - \u001b[1;30mSUCCESS\u001b[0m \u001b[1;32mTrained model id 10: sklearn.ensemble.RandomForestClassifier({'max_depth': 50, 'min_samples_split': 25, 'n_estimators': 150}) [afe9d61f915aed6702fc598ceb66fdaf] on train matrix 88033d4d2e731553062324d7403af43f. \u001b[0m\n",
            "\u001b[32m2021-12-07 22:29:24\u001b[0m - \u001b[1;30m   INFO\u001b[0m NumExpr defaulting to 2 threads.\n",
            "\u001b[32m2021-12-07 22:29:24\u001b[0m - \u001b[1;30m   INFO\u001b[0m getcrosstabs: attribute columns to perform crosstabs:teacher_prefix\n",
            "get_disparity_predefined_group()\n",
            "\u001b[32m2021-12-07 22:29:25\u001b[0m - \u001b[1;30m   INFO\u001b[0m get_group_value_fairness...\n",
            "\u001b[32m2021-12-07 22:29:25\u001b[0m - \u001b[1;30m   INFO\u001b[0m getcrosstabs: attribute columns to perform crosstabs:teacher_prefix\n",
            "get_disparity_predefined_group()\n",
            "\u001b[32m2021-12-07 22:29:26\u001b[0m - \u001b[1;30m   INFO\u001b[0m get_group_value_fairness...\n",
            "\u001b[32m2021-12-07 22:29:26\u001b[0m - \u001b[1;30m   INFO\u001b[0m Model 10 evaluation on test matrix 2a2ba0ccc318bbe74a99726a72c323b0 completed.\n",
            "\u001b[32m2021-12-07 22:29:27\u001b[0m - \u001b[1;30m   INFO\u001b[0m getcrosstabs: attribute columns to perform crosstabs:teacher_prefix\n",
            "get_disparity_predefined_group()\n",
            "\u001b[32m2021-12-07 22:29:28\u001b[0m - \u001b[1;30m   INFO\u001b[0m get_group_value_fairness...\n",
            "\u001b[32m2021-12-07 22:29:28\u001b[0m - \u001b[1;30m   INFO\u001b[0m getcrosstabs: attribute columns to perform crosstabs:teacher_prefix\n",
            "get_disparity_predefined_group()\n",
            "\u001b[32m2021-12-07 22:29:29\u001b[0m - \u001b[1;30m   INFO\u001b[0m get_group_value_fairness...\n",
            "\u001b[32m2021-12-07 22:29:29\u001b[0m - \u001b[1;30m   INFO\u001b[0m Model 10 evaluation on train matrix 88033d4d2e731553062324d7403af43f completed.\n",
            "\u001b[32m2021-12-07 22:29:29\u001b[0m - \u001b[1;30mVERBOSE\u001b[0m \u001b[34mTraining sklearn.ensemble.RandomForestClassifier({'max_depth': 50, 'min_samples_split': 25, 'n_estimators': 150}) [1e85f51c07613de12cd2f167417dc943] on train matrix 10f30faf4d136757ef3f11d9b3e5bdc2\u001b[0m\n",
            "\u001b[32m2021-12-07 22:29:30\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mModel 11, not found from previous runs. Adding the new model\u001b[0m\n",
            "\u001b[32m2021-12-07 22:29:30\u001b[0m - \u001b[1;30mSUCCESS\u001b[0m \u001b[1;32mTrained model id 11: sklearn.ensemble.RandomForestClassifier({'max_depth': 50, 'min_samples_split': 25, 'n_estimators': 150}) [1e85f51c07613de12cd2f167417dc943] on train matrix 10f30faf4d136757ef3f11d9b3e5bdc2. \u001b[0m\n",
            "\u001b[32m2021-12-07 22:29:32\u001b[0m - \u001b[1;30m   INFO\u001b[0m NumExpr defaulting to 2 threads.\n",
            "\u001b[32m2021-12-07 22:29:32\u001b[0m - \u001b[1;30m   INFO\u001b[0m getcrosstabs: attribute columns to perform crosstabs:teacher_prefix\n",
            "get_disparity_predefined_group()\n",
            "\u001b[32m2021-12-07 22:29:33\u001b[0m - \u001b[1;30m   INFO\u001b[0m get_group_value_fairness...\n",
            "\u001b[32m2021-12-07 22:29:33\u001b[0m - \u001b[1;30m   INFO\u001b[0m getcrosstabs: attribute columns to perform crosstabs:teacher_prefix\n",
            "get_disparity_predefined_group()\n",
            "\u001b[32m2021-12-07 22:29:34\u001b[0m - \u001b[1;30m   INFO\u001b[0m get_group_value_fairness...\n",
            "\u001b[32m2021-12-07 22:29:34\u001b[0m - \u001b[1;30m   INFO\u001b[0m Model 11 evaluation on test matrix cc681ad650fafd044897af6bd73ab167 completed.\n",
            "\u001b[32m2021-12-07 22:29:36\u001b[0m - \u001b[1;30m   INFO\u001b[0m getcrosstabs: attribute columns to perform crosstabs:teacher_prefix\n",
            "get_disparity_predefined_group()\n",
            "\u001b[32m2021-12-07 22:29:37\u001b[0m - \u001b[1;30m   INFO\u001b[0m get_group_value_fairness...\n",
            "\u001b[32m2021-12-07 22:29:37\u001b[0m - \u001b[1;30m   INFO\u001b[0m getcrosstabs: attribute columns to perform crosstabs:teacher_prefix\n",
            "get_disparity_predefined_group()\n",
            "\u001b[32m2021-12-07 22:29:38\u001b[0m - \u001b[1;30m   INFO\u001b[0m get_group_value_fairness...\n",
            "\u001b[32m2021-12-07 22:29:38\u001b[0m - \u001b[1;30m   INFO\u001b[0m Model 11 evaluation on train matrix 10f30faf4d136757ef3f11d9b3e5bdc2 completed.\n",
            "\u001b[32m2021-12-07 22:29:38\u001b[0m - \u001b[1;30mVERBOSE\u001b[0m \u001b[34mTraining sklearn.ensemble.RandomForestClassifier({'max_depth': 50, 'min_samples_split': 25, 'n_estimators': 150}) [9f8849dadb995060d03511f2e0e8c3e1] on train matrix f8772c9ca6484d2f32a7e8258f6dbc64\u001b[0m\n",
            "\u001b[32m2021-12-07 22:29:40\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mModel 12, not found from previous runs. Adding the new model\u001b[0m\n",
            "\u001b[32m2021-12-07 22:29:40\u001b[0m - \u001b[1;30mSUCCESS\u001b[0m \u001b[1;32mTrained model id 12: sklearn.ensemble.RandomForestClassifier({'max_depth': 50, 'min_samples_split': 25, 'n_estimators': 150}) [9f8849dadb995060d03511f2e0e8c3e1] on train matrix f8772c9ca6484d2f32a7e8258f6dbc64. \u001b[0m\n",
            "\u001b[32m2021-12-07 22:29:42\u001b[0m - \u001b[1;30m   INFO\u001b[0m NumExpr defaulting to 2 threads.\n",
            "\u001b[32m2021-12-07 22:29:42\u001b[0m - \u001b[1;30m   INFO\u001b[0m getcrosstabs: attribute columns to perform crosstabs:teacher_prefix\n",
            "get_disparity_predefined_group()\n",
            "\u001b[32m2021-12-07 22:29:43\u001b[0m - \u001b[1;30m   INFO\u001b[0m get_group_value_fairness...\n",
            "\u001b[32m2021-12-07 22:29:43\u001b[0m - \u001b[1;30m   INFO\u001b[0m getcrosstabs: attribute columns to perform crosstabs:teacher_prefix\n",
            "get_disparity_predefined_group()\n",
            "\u001b[32m2021-12-07 22:29:44\u001b[0m - \u001b[1;30m   INFO\u001b[0m get_group_value_fairness...\n",
            "\u001b[32m2021-12-07 22:29:44\u001b[0m - \u001b[1;30m   INFO\u001b[0m Model 12 evaluation on test matrix 76c9a74b579fcdc3747e18fdfa286e35 completed.\n",
            "\u001b[32m2021-12-07 22:29:46\u001b[0m - \u001b[1;30m   INFO\u001b[0m getcrosstabs: attribute columns to perform crosstabs:teacher_prefix\n",
            "get_disparity_predefined_group()\n",
            "\u001b[32m2021-12-07 22:29:46\u001b[0m - \u001b[1;30m   INFO\u001b[0m get_group_value_fairness...\n",
            "\u001b[32m2021-12-07 22:29:47\u001b[0m - \u001b[1;30m   INFO\u001b[0m getcrosstabs: attribute columns to perform crosstabs:teacher_prefix\n",
            "get_disparity_predefined_group()\n",
            "\u001b[32m2021-12-07 22:29:47\u001b[0m - \u001b[1;30m   INFO\u001b[0m get_group_value_fairness...\n",
            "\u001b[32m2021-12-07 22:29:47\u001b[0m - \u001b[1;30m   INFO\u001b[0m Model 12 evaluation on train matrix f8772c9ca6484d2f32a7e8258f6dbc64 completed.\n",
            "\u001b[32m2021-12-07 22:29:47\u001b[0m - \u001b[1;30m   INFO\u001b[0m Done. successes: 3, failures: 0\n",
            "\u001b[32m2021-12-07 22:29:48\u001b[0m - \u001b[1;30m   INFO\u001b[0m Starting parallelizable batch train/testing with 0 tasks, 2 processes\n",
            "\u001b[32m2021-12-07 22:29:48\u001b[0m - \u001b[1;30m   INFO\u001b[0m Done. successes: 0, failures: 0\n",
            "\u001b[32m2021-12-07 22:29:48\u001b[0m - \u001b[1;30mSUCCESS\u001b[0m \u001b[1;32mTraining, testing and evaluatiog models completed\u001b[0m\n",
            "\u001b[32m2021-12-07 22:29:48\u001b[0m - \u001b[1;30mSUCCESS\u001b[0m \u001b[1;32mAll matrices that were supposed to be build were built. Awesome!\u001b[0m\n",
            "\u001b[32m2021-12-07 22:29:48\u001b[0m - \u001b[1;30mSUCCESS\u001b[0m \u001b[1;32mAll models that were supposed to be trained were trained. Awesome!\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPXmtJ667osT"
      },
      "source": [
        "## Checking the results\n",
        "\n",
        "Confirming we got some models..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpfPG-nyq1Nk"
      },
      "source": [
        "import yaml\n",
        "from sqlalchemy.engine.url import URL\n",
        "from triage.util.db import create_engine\n",
        "import pandas as pd\n",
        "\n",
        "dbconfig = yaml.safe_load(database_yaml)\n",
        "db_url = URL(\n",
        "            'postgres',\n",
        "            host=dbconfig['host'],\n",
        "            username=dbconfig['user'],\n",
        "            database=dbconfig['db'],\n",
        "            password=dbconfig['pass'],\n",
        "            port=dbconfig['port'],\n",
        "        )\n",
        "\n",
        "db_engine = create_engine(db_url)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 810
        },
        "id": "dZnlWPbMrFN-",
        "outputId": "b8580e74-04a9-4dba-b59a-37fd8bdd9a5f"
      },
      "source": [
        "pd.read_sql('SELECT * FROM triage_metadata.models;', db_engine)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model_id</th>\n",
              "      <th>model_group_id</th>\n",
              "      <th>model_hash</th>\n",
              "      <th>run_time</th>\n",
              "      <th>batch_run_time</th>\n",
              "      <th>model_type</th>\n",
              "      <th>hyperparameters</th>\n",
              "      <th>model_comment</th>\n",
              "      <th>batch_comment</th>\n",
              "      <th>config</th>\n",
              "      <th>train_end_time</th>\n",
              "      <th>test</th>\n",
              "      <th>train_matrix_uuid</th>\n",
              "      <th>training_label_timespan</th>\n",
              "      <th>model_size</th>\n",
              "      <th>random_seed</th>\n",
              "      <th>built_in_triage_run</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>395896e2f4506e13d4ebe536c72f4d81</td>\n",
              "      <td>2021-12-07 22:27:22.721503</td>\n",
              "      <td>2021-12-07 22:27:22.344349</td>\n",
              "      <td>sklearn.tree.DecisionTreeClassifier</td>\n",
              "      <td>{'max_depth': 3, 'max_features': None, 'min_sa...</td>\n",
              "      <td>triage demo</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>2012-04-01</td>\n",
              "      <td>False</td>\n",
              "      <td>88033d4d2e731553062324d7403af43f</td>\n",
              "      <td>90 days</td>\n",
              "      <td>0.0625</td>\n",
              "      <td>908907174</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>58b2330d957c967f3e9de50a09eca3da</td>\n",
              "      <td>2021-12-07 22:27:22.728391</td>\n",
              "      <td>2021-12-07 22:27:22.344349</td>\n",
              "      <td>triage.component.catwalk.estimators.classifier...</td>\n",
              "      <td>{'C': 0.1, 'penalty': 'l1'}</td>\n",
              "      <td>triage demo</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>2012-04-01</td>\n",
              "      <td>False</td>\n",
              "      <td>88033d4d2e731553062324d7403af43f</td>\n",
              "      <td>90 days</td>\n",
              "      <td>0.0625</td>\n",
              "      <td>1656233507</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>fae0c1a55e7c9bd9fa9064b2cd481371</td>\n",
              "      <td>2021-12-07 22:27:52.231542</td>\n",
              "      <td>2021-12-07 22:27:22.344349</td>\n",
              "      <td>triage.component.catwalk.baselines.rankers.Per...</td>\n",
              "      <td>{'descend': False, 'feature': 'project_feature...</td>\n",
              "      <td>triage demo</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>2012-04-01</td>\n",
              "      <td>False</td>\n",
              "      <td>88033d4d2e731553062324d7403af43f</td>\n",
              "      <td>90 days</td>\n",
              "      <td>0.0625</td>\n",
              "      <td>1259133573</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>232a3978ccf34b167884daf702e8ed26</td>\n",
              "      <td>2021-12-07 22:27:52.840186</td>\n",
              "      <td>2021-12-07 22:27:22.402445</td>\n",
              "      <td>sklearn.tree.DecisionTreeClassifier</td>\n",
              "      <td>{'max_depth': 3, 'max_features': None, 'min_sa...</td>\n",
              "      <td>triage demo</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>2012-08-01</td>\n",
              "      <td>False</td>\n",
              "      <td>10f30faf4d136757ef3f11d9b3e5bdc2</td>\n",
              "      <td>90 days</td>\n",
              "      <td>0.0625</td>\n",
              "      <td>1106414652</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>b21e79f1c30cf98f035f493fd8dae06c</td>\n",
              "      <td>2021-12-07 22:28:01.561102</td>\n",
              "      <td>2021-12-07 22:27:22.402445</td>\n",
              "      <td>triage.component.catwalk.estimators.classifier...</td>\n",
              "      <td>{'C': 0.1, 'penalty': 'l1'}</td>\n",
              "      <td>triage demo</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>2012-08-01</td>\n",
              "      <td>False</td>\n",
              "      <td>10f30faf4d136757ef3f11d9b3e5bdc2</td>\n",
              "      <td>90 days</td>\n",
              "      <td>0.0625</td>\n",
              "      <td>897217774</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>dd806432f4bfd195aade5a559cf076d2</td>\n",
              "      <td>2021-12-07 22:28:28.436616</td>\n",
              "      <td>2021-12-07 22:27:22.402445</td>\n",
              "      <td>triage.component.catwalk.baselines.rankers.Per...</td>\n",
              "      <td>{'descend': False, 'feature': 'project_feature...</td>\n",
              "      <td>triage demo</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>2012-08-01</td>\n",
              "      <td>False</td>\n",
              "      <td>10f30faf4d136757ef3f11d9b3e5bdc2</td>\n",
              "      <td>90 days</td>\n",
              "      <td>0.0625</td>\n",
              "      <td>1431439151</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>4b37802241efcfae1e82485fb3f48ef9</td>\n",
              "      <td>2021-12-07 22:28:37.678829</td>\n",
              "      <td>2021-12-07 22:27:22.447742</td>\n",
              "      <td>sklearn.tree.DecisionTreeClassifier</td>\n",
              "      <td>{'max_depth': 3, 'max_features': None, 'min_sa...</td>\n",
              "      <td>triage demo</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>2012-12-01</td>\n",
              "      <td>False</td>\n",
              "      <td>f8772c9ca6484d2f32a7e8258f6dbc64</td>\n",
              "      <td>90 days</td>\n",
              "      <td>0.0625</td>\n",
              "      <td>1463730397</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>21c8665d4b12f8f095c90dd0bf0d5f68</td>\n",
              "      <td>2021-12-07 22:28:38.689047</td>\n",
              "      <td>2021-12-07 22:27:22.447742</td>\n",
              "      <td>triage.component.catwalk.estimators.classifier...</td>\n",
              "      <td>{'C': 0.1, 'penalty': 'l1'}</td>\n",
              "      <td>triage demo</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>2012-12-01</td>\n",
              "      <td>False</td>\n",
              "      <td>f8772c9ca6484d2f32a7e8258f6dbc64</td>\n",
              "      <td>90 days</td>\n",
              "      <td>0.0625</td>\n",
              "      <td>1879462244</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>4</td>\n",
              "      <td>3510f611b7ec6e3c4751ba0f81170d63</td>\n",
              "      <td>2021-12-07 22:29:15.286520</td>\n",
              "      <td>2021-12-07 22:27:22.447742</td>\n",
              "      <td>triage.component.catwalk.baselines.rankers.Per...</td>\n",
              "      <td>{'descend': False, 'feature': 'project_feature...</td>\n",
              "      <td>triage demo</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>2012-12-01</td>\n",
              "      <td>False</td>\n",
              "      <td>f8772c9ca6484d2f32a7e8258f6dbc64</td>\n",
              "      <td>90 days</td>\n",
              "      <td>0.0625</td>\n",
              "      <td>827031307</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>afe9d61f915aed6702fc598ceb66fdaf</td>\n",
              "      <td>2021-12-07 22:29:22.295662</td>\n",
              "      <td>2021-12-07 22:27:22.344349</td>\n",
              "      <td>sklearn.ensemble.RandomForestClassifier</td>\n",
              "      <td>{'max_depth': 50, 'n_estimators': 150, 'min_sa...</td>\n",
              "      <td>triage demo</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>2012-04-01</td>\n",
              "      <td>False</td>\n",
              "      <td>88033d4d2e731553062324d7403af43f</td>\n",
              "      <td>90 days</td>\n",
              "      <td>0.0625</td>\n",
              "      <td>1443952767</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>1e85f51c07613de12cd2f167417dc943</td>\n",
              "      <td>2021-12-07 22:29:29.629557</td>\n",
              "      <td>2021-12-07 22:27:22.402445</td>\n",
              "      <td>sklearn.ensemble.RandomForestClassifier</td>\n",
              "      <td>{'max_depth': 50, 'n_estimators': 150, 'min_sa...</td>\n",
              "      <td>triage demo</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>2012-08-01</td>\n",
              "      <td>False</td>\n",
              "      <td>10f30faf4d136757ef3f11d9b3e5bdc2</td>\n",
              "      <td>90 days</td>\n",
              "      <td>0.0625</td>\n",
              "      <td>1252071336</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>9f8849dadb995060d03511f2e0e8c3e1</td>\n",
              "      <td>2021-12-07 22:29:39.147822</td>\n",
              "      <td>2021-12-07 22:27:22.447742</td>\n",
              "      <td>sklearn.ensemble.RandomForestClassifier</td>\n",
              "      <td>{'max_depth': 50, 'n_estimators': 150, 'min_sa...</td>\n",
              "      <td>triage demo</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>2012-12-01</td>\n",
              "      <td>False</td>\n",
              "      <td>f8772c9ca6484d2f32a7e8258f6dbc64</td>\n",
              "      <td>90 days</td>\n",
              "      <td>0.0625</td>\n",
              "      <td>590967750</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    model_id  model_group_id  ... random_seed built_in_triage_run\n",
              "0          1               2  ...   908907174                   1\n",
              "1          2               3  ...  1656233507                   1\n",
              "2          3               4  ...  1259133573                   1\n",
              "3          4               2  ...  1106414652                   1\n",
              "4          5               3  ...   897217774                   1\n",
              "5          6               4  ...  1431439151                   1\n",
              "6          7               2  ...  1463730397                   1\n",
              "7          8               3  ...  1879462244                   1\n",
              "8          9               4  ...   827031307                   1\n",
              "9         10               1  ...  1443952767                   1\n",
              "10        11               1  ...  1252071336                   1\n",
              "11        12               1  ...   590967750                   1\n",
              "\n",
              "[12 rows x 17 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyC6b5e07wBl"
      },
      "source": [
        "Confirming we saved predictions..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "1H_tiuoUrYzS",
        "outputId": "51487d43-9265-4258-c10f-73743fade1f5"
      },
      "source": [
        "pd.read_sql('SELECT * FROM test_results.predictions LIMIT 5;', db_engine)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model_id</th>\n",
              "      <th>entity_id</th>\n",
              "      <th>as_of_date</th>\n",
              "      <th>score</th>\n",
              "      <th>label_value</th>\n",
              "      <th>rank_abs_no_ties</th>\n",
              "      <th>rank_abs_with_ties</th>\n",
              "      <th>rank_pct_no_ties</th>\n",
              "      <th>rank_pct_with_ties</th>\n",
              "      <th>matrix_uuid</th>\n",
              "      <th>test_label_timespan</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>254981</td>\n",
              "      <td>2012-04-12</td>\n",
              "      <td>0.99742</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00258</td>\n",
              "      <td>0.00259</td>\n",
              "      <td>2a2ba0ccc318bbe74a99726a72c323b0</td>\n",
              "      <td>90 days</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>249195</td>\n",
              "      <td>2012-05-12</td>\n",
              "      <td>0.99485</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00515</td>\n",
              "      <td>0.00518</td>\n",
              "      <td>2a2ba0ccc318bbe74a99726a72c323b0</td>\n",
              "      <td>90 days</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>255422</td>\n",
              "      <td>2012-04-09</td>\n",
              "      <td>0.99227</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0.00773</td>\n",
              "      <td>0.00777</td>\n",
              "      <td>2a2ba0ccc318bbe74a99726a72c323b0</td>\n",
              "      <td>90 days</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>253874</td>\n",
              "      <td>2012-04-18</td>\n",
              "      <td>0.98969</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0.01031</td>\n",
              "      <td>0.01036</td>\n",
              "      <td>2a2ba0ccc318bbe74a99726a72c323b0</td>\n",
              "      <td>90 days</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>250376</td>\n",
              "      <td>2012-05-09</td>\n",
              "      <td>0.98711</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>0.01289</td>\n",
              "      <td>0.01295</td>\n",
              "      <td>2a2ba0ccc318bbe74a99726a72c323b0</td>\n",
              "      <td>90 days</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   model_id  entity_id  ...                       matrix_uuid  test_label_timespan\n",
              "0         3     254981  ...  2a2ba0ccc318bbe74a99726a72c323b0              90 days\n",
              "1         3     249195  ...  2a2ba0ccc318bbe74a99726a72c323b0              90 days\n",
              "2         3     255422  ...  2a2ba0ccc318bbe74a99726a72c323b0              90 days\n",
              "3         3     253874  ...  2a2ba0ccc318bbe74a99726a72c323b0              90 days\n",
              "4         3     250376  ...  2a2ba0ccc318bbe74a99726a72c323b0              90 days\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_vwKbQo727Q"
      },
      "source": [
        "Location of triage outputs..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tyx1QXJ3sAtQ",
        "outputId": "5de22d30-11bd-4d1e-8101-dcac062c414f"
      },
      "source": [
        "!ls triage_output/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "matrices  trained_models\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnM6vADdvx-N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "689efa3f-5a62-40d6-f087-27073d2a1758"
      },
      "source": [
        "!ls -la triage_output/matrices/\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 128\n",
            "drwxr-xr-x 2 root root  4096 Dec  7 22:27 .\n",
            "drwxr-xr-x 4 root root  4096 Dec  7 22:27 ..\n",
            "-rw-r--r-- 1 root root 17352 Dec  7 22:27 10f30faf4d136757ef3f11d9b3e5bdc2.csv.gz\n",
            "-rw-r--r-- 1 root root  7029 Dec  7 22:27 10f30faf4d136757ef3f11d9b3e5bdc2.yaml\n",
            "-rw-r--r-- 1 root root  3950 Dec  7 22:27 2a2ba0ccc318bbe74a99726a72c323b0.csv.gz\n",
            "-rw-r--r-- 1 root root  3369 Dec  7 22:27 2a2ba0ccc318bbe74a99726a72c323b0.yaml\n",
            "-rw-r--r-- 1 root root  6136 Dec  7 22:27 76c9a74b579fcdc3747e18fdfa286e35.csv.gz\n",
            "-rw-r--r-- 1 root root  3345 Dec  7 22:27 76c9a74b579fcdc3747e18fdfa286e35.yaml\n",
            "-rw-r--r-- 1 root root  8953 Dec  7 22:27 88033d4d2e731553062324d7403af43f.csv.gz\n",
            "-rw-r--r-- 1 root root  4125 Dec  7 22:27 88033d4d2e731553062324d7403af43f.yaml\n",
            "-rw-r--r-- 1 root root 10533 Dec  7 22:27 cc681ad650fafd044897af6bd73ab167.csv.gz\n",
            "-rw-r--r-- 1 root root  3393 Dec  7 22:27 cc681ad650fafd044897af6bd73ab167.yaml\n",
            "-rw-r--r-- 1 root root 23340 Dec  7 22:27 f8772c9ca6484d2f32a7e8258f6dbc64.csv.gz\n",
            "-rw-r--r-- 1 root root  9981 Dec  7 22:27 f8772c9ca6484d2f32a7e8258f6dbc64.yaml\n"
          ]
        }
      ]
    }
  ]
}